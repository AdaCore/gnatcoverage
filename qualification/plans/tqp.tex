\documentclass {report}
\usepackage{couverture}

\usepackage{color}
\definecolor{light-gray}{gray}{0.85}
\usepackage{listings}
\lstset{backgroundcolor=\color{light-gray}}

\begin{document}
\title{\huge
  \xcov{}\\
  Tool Qualification Plan\\ \ \\
  \large \textbf{Document Version 1.0}}

\maketitle
\tableofcontents

\chapter{Document introduction}

\section{Document purpose}
The purpose of this document is to describe the applicable processes to
qualify \xcov{} in a DO-178B and DO-178C context.

\section{Authors}
\begin{tabular}{|c|c|c|}
\hline
\textbf{Name} & \textbf{Company} & \textbf{Email} \\ \hline
Matteo Bordin & AdaCore & bordin@adacore.com \\ \hline
Olivier Hainque & AdaCore & hainque@adacore.com \\ \hline
\end{tabular}

\section{Major revision history}

The evolution of this document is automatically tracked by the configuration
management system. Here we just provide the major revision history.  \ \\ \\
\begin{tabular}{|c|c|c|}
\hline
\textbf{Version} & \textbf{Date} & \textbf{Comment} \\ \hline
 &  &  \\ \hline
\end{tabular}

\section{Ongoing work}

\begin{itemize}
\item%
  Need to integrate big blob on the tor/testbase orgnaisation.
%
\item%
  Need to clarify the notion of qualified interface vs command line
  options and coding standard
%
\item%
  Need to fill missing briefs on the various ``Plan'' documents in
  the Qualification Data chapter
%
\item%
  Need to complete/clarify the Preparing for Qualified Use chapter,
  in particular who does and produces what (e.g. who runs the tests etc).
\end{itemize}

% **************************************************************************
\include{doc_introduction}

% **************************************************************************
\chapter{Tool Overview \& Qualified Interface}


\section{Tool overview}

\xcov{} is a tool designed to assess the object or source level coverage
achieved by a testing campaign on software.
%
\xcov{} operates without any instrumentation of the original program, on
code generated by the same compiler as the one producing the executable
deployed on the target hardware.
%
For source level coverage assessments, \xcov{} analyses two core pieces of
information:

\begin{Itemize}
%
\item The list of object instructions executed by the test-sets of interest,
  also known as \E{execution traces}, produced by an instrumented execution
  environment;
%
\item Tables that allow mapping machine instructions to precise source
  constructs (statements, decisions, conditions), produced by the compiler.
\end{Itemize}

Detailed information on the tool capabilities and characteristics is available
in the ``\xcov{} Fundamentals and Users Guide'' as well as in \adaeurope and
\erts.

\section {Sought certification credit}

\xcov{} aims at automating the structural coverage assessment activities
required by the Software Verification Process of DO-178.
%
This assessment is mandatory for levels A, B, and C, with more stringent
requirements for the more critical levels (table A7, objectives 5-7): \mcdc{},
\dc{} and \stc{} for level A ; \dc{} and \stc{} for level B, and \stc{} for
 level C.

\xcov{} is qualified as a \emph{verification tool}, with a Tool Qualification
Level 5 (TQL5) in DO-178C terms.
%
Consequently, as long as uses comply with the qualified interface described in
section \ref{sec:qual-interface}, applicants may use \xcov{}'s output as
certification evidence and certification authorities shall consider \xcov{}'s
output \emph{as good as} the output of a manual activity.

\section{Qualified interface}
\label{sec:qual-interface}

To produce reports suitable for use as certification evidence, \xcov{} shall
be used as follows:

\begin{enumerate}
\item Build the executable application using the GNAT Pro toolchain identified
  in the delivery file (see section \ref{sec:delivery}), obeying the
  compilation options and coding standard documented there.

\item To produce an execution trace file \T{<TRACE>}, run the \T{<APP>}
  executable program within the instrumented execution environment using the
  following command line:\\

\T{xcov run --target=<TARGET> --level=<LEVEL> <APP> -o <TRACE>} \\

... where \T{<TARGET>} identifies the target platform (as in the GNAT Pro
toolchain prefixes, e.g.  powerpc-elf), and \T{<LEVEL>} designates the
coverage criteria to assess: \T{stmt}, \T{stmt+decision} or \T{stmt+mcdc};

\item To produce the assessment \T{<REPORT>} file, feed the execution traces
  of interest to the coverage analyzer using the following command line:\\

\texttt{xcov coverage --annotate=report --level=<LEVEL> \\
  --scos=@alis.list @traces.list -o <REPORT>} \\

... where \T{<LEVEL>} is the same as for \T{xcov run}, \T{traces.list} is a
file containing the list of execution traces to operate on, and \T{alis.list}
is a file containing the list of GNAT Pro ALI file names corresponding to the
source units for which coverage is to be assessed.

When the \T{traces.list} input lists multiple traces, \xcov{} consolidates the
coverage achieved by all the corresponding executions as if they all happened
in sequence as a single one.

The output report format is documented in an appendix of the \xcov{}
Fundamentals and Users Guide.

\end{enumerate}


% **************************************************************************
\chapter{Tool development and verification standards}

\section{General directions}

To elaborate how the tool should behave and assess that it produces reliable
outputs, useable as certification evidence, we provide:

\begin{Itemize}
\item%
  An explicit description of the expected behavior as a set of \term{Tool
    Operational Requirements} for nominal use conditions, and
\item%
  A set of executable \term{Test Cases} associated with each requirement,
  exercized in an automated manner to validate that the behavior indeed
  corresponds to expectations.
\end{Itemize}

Multiple aspects of the tool behavior have to be considered, and we
distinguish different categories of tool operational requirements for this
purpose.
%
To start with:

\begin{enumerate}
\item \textbf{Coverage of isolated source constructs.}
%
This category focuses on the users' expectations for the coverage of
specific source constructs (if statements, loop, blocks, etc) with respect to
a particular coverage metric.
%
\xcov{}'s qualified output focuses on cases of absence of (or partial)
coverage, so requirements of this category typically express conditions when
coverage shall be reported as \emph{not} achieved;
%
for example: \emph{"A boolean decision exercized only one way shall be
reported as only partially covered"}.

Individual requirements in this category target a single language construct.
%
The use of programming language reference manuals provides a significant
contribution in identifying the constructs of interest.

Testcases for this kind of TORs typically exercise the same construct in
various ways, for example by causing a boolean expression to be evaluated just
to True or False, and verify that results are are expected in all the
variations.

\item \textbf{General coverage analysis facilities.}
%
This category focuses on general facilities offered by the tool, not at all
tied to a particular language construct, such as the support for coverage
exemptions, or consolidation capabilities.

Testcases for requirements in this category play two roles: validate the tool
behavior with respect to the stated requirement, of course, and exercize the
tool on code where mutliple language features are mixed together.
%
Having tests for such mixes is necessary and there is no constraint on this
account here, so we take the opportunity.
% 
And in any case, the facilities to validate typically require a mix of
constructs to be tested properly.
\end{enumerate}

For those two first categories, our principal focus is to assess that \xcov{}
is \emph{sound}, that is, to make sure that violations of a given coverage
criterion are detected.
%
Nevertheless, our testsuite driver expects a strict one-to-one match between
result expectations stated by test writers in testcases and the diagnostics
emitted by the tool, such that every reported violation must have been stated
as expected and every expected violation must be reported for a test to pass.

Beyond all that, we have identified two other requirement categories of use:

\begin{enumerate}
\item \textbf{Compliance of the output report with the documented format.}
%
The documented output report format is a part of the tool qualified interface.
% 
This category of requirements focuses on well identified aspects of that
report format.

Dedicated testcases are designed to verify that all the mandatory pieces are
there.
%
Part of these requirements are also implicitly validated by the execution of
all the coverage checking testcases in other categories, where specific
sections of the report are scanned to search for criteria violation messages
and compare them with user specified expectations.

\item \textbf{Representativeness of the coverage assessment environment.}
%
Eventhough compiled with the final target compiler, the qualification Test
Cases are not bound to run and be tested on the final hardware as pieces of
the applicative system.
%
This category of requirements aims at validating that the instrumented
execution environment used by \xcov{} to assess coverage is representative of
the final hardware.

TORs in this category are validated by testcases comparing the output of
executables run via \xcov{} and on the final target processor, together with
the addition of functional assertions in all the testcases of the other
categories.
%
Such assertions may be viewed as partial specifications of the final target
environment expected behavior, designed to cause test failures when the
assessment environment behavior deviates from the target model.
\end{enumerate}

\section{Operational organization}

TBC

\subsection{Tool Operational Requirements}
A physical folder on the repository is associated to each TOR. The name of the folder is the id of the TOR. All qualification artifacts derived from a TOR are stored as either files or folders contained in the folder of the parent TOR. The TOR textual specification is contained in a file always named \texttt{req.txt}.

\subsection{Test cases}
Explicit description of test cases (when necessary) is contained in the \texttt{req.txt} of the parent TOR under the section "Testing strategy". Source code for test cases is contained in the \texttt{src} sub-folder and source files do \emph{not} start with the \texttt{test\_} prefix. 

\subsection{Tests source code}
Source code for tests is contained in the \texttt{src} sub-folder; source files start with the \texttt{test\_} prefix. 


% **************************************************************************
\chapter{Qualification Data}

\section{Overview}
\label{sec:qd-overview}

Eventually, \xcov{}'s qualification data materializes as a set of files and
documents, summarized in the table below:

\begin{tabular}{|c|c|c|}
\hline
\textbf{Data} & \textbf{Provided by} & \textbf{File} \\ \hline
Tool Qualification Plan & Qualification Team & tqp.pdf \\ \hline
Software Configuration Management Plan & Qualification Team & scmp.pdf \\ \hline
Software Quality Assurance Plan & Quality Assurance Team & sqap.pdf \\ \hline
Tool Operational Requirements & Development Team & tor\_tc\_ts.pdf \\ \hline
Test Cases \& Tests & " & " \\ \hline
Tests Results & Development Team & ts\_results.pdf \\ \hline
Delivery file & Qualification Team & section \ref{sec:delivery} \\ \hline
Verification results analysis & User & user-specific \\ \hline
\xcov{} Fundamentals \& User's Guide & Development Team & xcov\_ug.pdf \\ \hline
\end{tabular}

The Tool Qualification, Software Configuration Management and Software Quality
Assurance Plans are generic qualification data, \emph{not} specific to a given
release of \xcov{}.
%
All the other files and documents are specific to a given \xcov{}
release.

\section{Tool Qualification Plan}

This document.

\section{Software Configuration Management Plan}

TBC

\section{Software Quality Assurance Plan}

TBC

\section{Operational Requirements and Test Cases}

TBC

\section{Delivery file}
\label{sec:delivery}

Each delivery qualified for use to produce certification evidence includes a
\T{delivery.txt} synthesis file which contains:

\begin{Itemize} 
\item%
  The description of the qualification environment, as defined by the section
  \ref{sec:equivalence} to allow equivalence checks by users;
  %
\item%
  The version of all the files listed in section \ref{sec:qd-overview}, as
  part of the qualification data;
  %
\item%
  A list of the known problems in this particular delivery;
  %
\item%
  A description of the GNAT Pro compilation options and coding standard that
  need to be obeyed, delivery specific part of the tool qualified interface.
\end{Itemize}

% **************************************************************************
\chapter{Preparing for Qualified Use}

The user needs to perform a set of activities, either in the scope of \xcov{}
qualification or \xcov{} usage.

\section{\xcov{} qualification}

To finalise the qualification of \xcov{}, the user needs to:

\begin{enumerate}
%
\item \textbf{Reference \xcov{} in the PSAC}, identifying \xcov{} as a
  verification tool requiring qualification because it contributes to take
  certification credit by automating some (otherwise manual) activities.
%
\item \textbf{Assess the equivalence between the qualification environment and
  the operational environment} (see section \ref{sec:equivalence}).
%
\item \textbf{Put qualification data under configuration management}.
\end{enumerate}

\section{\xcov{} usage}

Users needs to perform the following activities to assure \xcov{} exhibits
a qualified behaviour:

\begin{enumerate}
\item \textbf{Install \xcov{} in the Operational Environment};
%
\item \textbf{Check that \xcov{} is used following its qualified interface},
    as described in section \ref{sec:qual-interface};
%
\item \textbf{Check that \xcov{} is used in a way compliant to its known
  constraints and open problems}, as documented in the delivery file.
%
\item \textbf{Update the Environment Configuration Index} by including the delivery file and test results (see section \ref{sec:qd-overview} for the corresponding files).
%
\item \textbf{Update the Software Accomplishment Summary} for:
\begin{itemize}
\item Objectives 5, 6 and 7 of table A7 for level A software.
\item Objectives 6 and 7 of table A7 for level B software.
\item Objective 7 of table A7 for level C software.
\end{itemize}
%
\item \textbf{Update the Software Accomplishment Summary} for the
  qualification status of \xcov{}.
\end{enumerate}

\section{Environment equivalence}
\label{sec:equivalence}

For the whole set of qualification material to be consistent, the
qualification and user environments must be equivalent.
%
Given our internal knowledge of \xcov{}, we deem the following data sufficient
to establish equivalence of environments:

\begin{enumerate}
\item the name of the GNAT Pro executable;
\item the GNAT Pro version number;
\item the \xcov{} version number;
\item the host operating system and its version;
\end{enumerate}

The value for all the items above for the qualification environment are
contained in the delivery file (section \ref{sec:delivery}). Test execution
results are produced in an environment which is equivalent to the one
described in the delivery file.

\end{document}
