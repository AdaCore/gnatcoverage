\input texinfo  @c -*-texinfo-*-

@c %**start of header
@c oooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo
@c                                                                            o
@c                            XCOV DOCUMENTATION                              o
@c                                                                            o
@c oooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo

@setfilename xcov.info
@settitle Xcov documentation
@c %**end of header

@macro xcov
@command{xcov}
@end macro

@macro xrun
@command{xcov run}
@end macro

@macro h {text}  @c style for headers in descriptive tables
@dfn{\text\}
@end macro

@macro bibref {entry}
[@cite{\entry\}]
@end macro

@macro gcc
@sc{gcc}
@end macro

@macro gnat
@sc{gnat}
@end macro

@macro qemu
@sc{qemu}
@end macro

@macro gcov
@sc{gcov}
@end macro

@c Directory where the Explore guide example is stored
@set explore_dir examples/explore

@titlepage
@title Xcov Fundamentals & User's Guide
@end titlepage

@contents

@c *******************************************************************
@c *                         ABOUT THIS DOCUMENT                     *
@c *******************************************************************

@node Top
@top  About this Document

@noindent
This document introduces the fundamentals of Xcov, a non intrusive
structural coverage analysis framework, together with a toolset user's
guide.

@ref{scov-basics} introduces the contextual elements of the Xcov's
development. This includes a general definition and rationale for
``Structural Coverage Analysis'', the process model we consider and a
description of different possible kinds of analysis activities.

@ref{xcov-grounds} describes the Xcov framework core operation mode and
capabilities.

@ref{xcov-guide} is the toolset user's guide, with details on the tools
command lines, use examples for various situations and outputs
interpretation guidelines.

Various concepts are illustrated with examples throughout.
@
Most of the program sources for these examples are taken from toy
``explorer robot'' application, developed just for this illustrative
purpose and introduced in @ref{explore}.


@menu
* scov-basics::  Structural Coverage Basics
* xcov-grounds:: Xcov Fundamentals
* xcov-guide::   Xcov User's Guide
* explore::      The Explore Guide Example
@end menu


@c *******************************************************************
@c *                      COVERAGE ANALYSIS BASICS                   *
@c *******************************************************************

@node scov-basics,xcov-grounds,Top,Top
@chapter Structural Coverage Analysis Basics

@section General Definition & Rationale
@noindent
Structural coverage analysis may be viewed as a software development
activity aimed at analysing which pieces of an application source and/or
machine code are exercised by executions of the application software.
@c
There may be several reasons why such an activity is performed and extra
details about what exactly is to be evaluated.

One of our target applications is the use of coverage analysis in
software certification processes such as the DO-178B standard enforced
in the civilian avionics domain.
@c
In this context, the application code and the test sequences are both
derived from a common set of requirements, independently, and structural
coverage analysis is one of the means to confront the pieces.
@c
Essentially, it allows an assessment of the testing campain quality and
helps the identification of various forms of pointless code or of
requirements imprecision/incompleteness.

In the following sections we introduce the elements of a coverage
analysis process together with @dfn{terms} to be reused throughout this
document.

@section Process Model

@subsection Process Abstractions
@noindent
A typical coverage analysis elementary process comprises three principal
steps:
@enumerate
@item
A binary @dfn{executable program} is produced from a set of program
@dfn{sources} by development toolchains with compilers, linkers, etc.

@item
The executable program runs within an @dfn{execution environment}, and
this execution produces @dfn{raw coverage data} about paths it
exercises.

@item
The raw coverage data is interpreted or @dfn{mapped} into some user
readable representation.
@end enumerate

As an illustrative example, the common @gcc{}/@gcov{} process is exactly
along those lines: the program is compiled and linked by @gcc{}
@bibref{gcc} with special command-line options, execution produces a
binary data file and @gcov{} is then used to generate annotated sources
from the original files, the executable and the execution data.
@c
Below is an example with a simple test of the Explore queues
abstraction, compiled with the @gnat{} toolchain for Ada:

@smallexample

# Build with gcov related options - produces executable program

    $ gnatmake test_queues.adb -fprofile-arcs -ftest-coverage

# Run program - produces raw coverage data files (queues.gcda, ...)

    $ ./test_queues

# Map to user representation - produces annotated sources (queues.adb.gcov, ...)
 
    $ gcov test_queues

@end smallexample
  
The annotations are in the first column for each source line: @code{'-'}
indicates there is no associated object code, numbers indicates the
number of times code for this line was executed, and @code{'#'} signs
indicates object code never executed:

@smallexample

        [...]
        1:    9:procedure Test_Queues is
        -:   10:   package Integer_Queues is new Queues (Data_Type => Integer);
        -:   11:   use Integer_Queues;
        -:   12:
        -:   13:   X : Integer;
        1:   14:   Q : Integer_Queues.Queue (Capacity => 1);
        -:   15:begin
        1:   16:   Push (12, Q);
        1:   17:   Pop (X, Q);
        1:   18:   if X /= 12 then
    #####:   19:      raise Program_Error;
        -:   20:   end if;
        -:   21:end;

@end smallexample

In this excerpt, the never executed code is expected to show up this way,
as it is intended to trigger only when the test didn't behave as it should.
@c
This points at an important distinction to make: the @code{Test_Queues}
procedure in this example is @dfn{testing code} written to exercise
pieces of the @code{Queues} abstraction, and only the latter will be an
actual part of the application.
@c
Most of the time, we're only interested in the coverage results for such
@dfn{applicative} code.

The form of the raw information depends on the coverage analysis toolset
technology.
@c
This is most often binary data.
@c
The production of raw coverage data at run time always involves some
sort of @dfn{instrumentation} to have the execution produce information
it normally wouldn't produce.
@c
This may be achieved in several possible manners:
@itemize @bullet
@item @dfn{Source Instrumentation}:
The coverage analysis toolset adds explicit statements and data
structures to the program source to maintain the coverage state.
@c
This is what many commercial products do.

@item @dfn{Object Instrumentation}:
The development toolchain inserts extra machine state and instructions
in the program executable object code.
@c
This is the @gcc{}/@gcov{} approach.

@item @dfn{Environment Instrumentation}:
The execution environment is setup to produce a trace of the program paths
taken at the machine instruction level, leaving the program code untouched.
@c
This is what solutions based on hardware probes or on instrumented
virtual execution environments do.

@end itemize

There are variants of each technique in the field, each with its own set
of advantages and drawbacks compared to others.
@c
While the base process applies to many situations, refinements are
useful in some cases, as outlined in the following sections.

@subsection Data Capitalization & Consolidation
@noindent
Proper coverage of applicative code often requires several test
executions on possibly disjoint pieces of the final system, with each
test providing its own partial coverage outcome.
@c
@dfn{Capitalization} denotes the storage of the partial results and
@dfn{Consolidation} denotes the construction of a unified view out of
partial results gathered together.

Different tests could for instance be several executions of the same
program with behavior differences caused by external input variations.
@c
They could also be executions of different programs exercizing different
units of the applicative code or common applicative code with different
parameters.

To illustrate, consider a common data structure implementation such as
the bounded @code{Queues} Ada package in the Explore example.
@c
To honor a common requirement, it contains simple error handling code so
that an "Ada exception X is raised on attempts to extract an item out of an
empty queue", and we expect this code not to be exercised in regular
executions.
@c
It remains applicative code, still, and even the weakest DO-178B
certification level requires tests to cover it, to make sure that at least
minimal checks on its behavior with respect to requirements were performed.
@c
Something has to be done outside nominal executions in this case.
@c
One possibility is to construct a separate program dedicated to just
testing this abstraction, which would force an artificial queue underflow.

The point is that one-shot full coverage is generally not possible in
complex situations and the example shows it is already partially
impossible with only regular Explore executions.
@c
System integration is most often a delicate process, not possible before
late stages of the project, and it is often useful or simply unavoidable
to perform coverage analysis on segregated pieces first.

Besides, even if full coverage a some applicative components could
theortically be achieved from a single execution, it is often just more
convenient or sensible to be able to reach the goal in an incremental
fashion.
@c
In the Explore case, for instance, a strategy like "purpose is to maximize
the entire application coverage by running a minimal number of sessions"
would be a pain and actually go against the requirements based testing
philosophy.
@c
One instead typically runs different sessions to verify different
specific application requirements, each session produces its own
coverage data.

@dfn{Consolidation} denotes the process of gathering the capitalized
coverage information for the various pieces of a system into a unified
view, with explicit input on what pieces are expected to have been
covered.
@c
Pieces for which coverage data is expected but not available are
identified and data for pieces of no interest (e.g. unit test harness)
may be abstracted away.
@c
The need for coverage data consolidation often correlates with testing
strategies: whether coverage data is obtained from unit testing of
individual components, from integration testing of the system as a whole,
from some intermediate organisation, or possibly from a mix of all these.


@subsection Process Integration
@noindent
As hinted by the previous sections, coverage analysis is a potentially
complex activity, which requires potentially complex metrics on
potentially complex software involved in potentially complex project
development cycles.

@dfn{Process integration} refers to the organization of the analysis
toolset that will provide consistent and easy access to all the features
of interest for a given project.
@c
The toolset needs to be both powerful enough to provide the desired
functionalities and flexible enough to accomodate the various possible
project organizations in the field.

@section Coverage Analysis Classification
@noindent
Coverage analysis always involves the evaluation of various
@dfn{coverage quantifiers} or @dfn{metrics} such as ``what percentage of
my program source statements or of the corresponding machine code was
exercised (covered) by this set of executions?''.
@c
In practice, this is most often refined down at the module or subprogram
level and comes together with detailed reports about the bits which were
exercised and those that were not.
@c
The process is typically driven by specific objectives like ``tests
should result in coverage of 100% of the application program source
statements''.
@c
Every toolset offers its own spectrum of analysis possibilities, with
variations in the implementation schemes.
@c
We distinguish two broad classes of activities: @dfn{source} and
@dfn{object} coverage analysis.

@subsection Object Coverage Analysis
@noindent
Object Coverage Analysis focuses on machine object code coverage,
with two essential quantifiers:

@itemize @bullet
@item @dfn{Object Instruction Coverage (OIC)} ;
which/how-much of the program machine instructions were exercised by a
set of program executions.

@item @dfn{Object Branch Coverage (OBC)} ;
OIC + indications on the machine decisions taken at each machine
conditional branch instruction.
@end itemize

Results can be rendered on a representation of the machine code, for
example as an annotated assembly output.
@c
They can also be rendered on a representation of the program sources,
for example by way of annotations for each source line to synthesize
information about all the machine code generated for that line.
@c
The focus is always on machine code coverage, in any case, and source
annotations in this context are just a means to organize and hilight
machine code properties of interest for the end user.

@subsection Source Coverage Analysis
@noindent
Source Coverage Analysis focuses on user source code and simply
abstracts the machine code away.
@c
The DO-178B structural coverage criteria operate at this level, with
quantifiers defined over three core elements:

@itemize @bullet
@item @dfn{Source statement},
in the usual programming language sense.

@item @dfn{Decision},
defined as ``a Boolean expression composed of conditions and zero or
more Boolean operators.''.

@item @dfn{Condition},
defined as ``a decision without a Boolean operator'' with an extra
detail: ``If a condition appears more than once in a decision, each
occurrence is a distinct condition.''.
@end itemize

@noindent The quantifiers are as follows:
@itemize @bullet
@item @dfn{Source Statement Coverage (SSC)} ;
which/how-much of the source statements were exercised by a set of
program executions.

@item @dfn{Source Decision Coverage (SDC)} ;
SSC + indications on the values taken by each logical decision and of
which entry/exit points were exercised.

@item @dfn{Source Modified Condition/Decision Coverage (SMCDC)} ;
SDC + indications on which conditions took their two possible outcome
and which were shown to have independent effect on their decisions out
of a set of program executions.
@end itemize

The quantifier names are often used standalone to denote coverage
objectives, for instance ``achieving Source Statement Coverage'' denotes
covering 100% of the program source statements.
@c      
The ``source'' part is often omitted and implicitly assumed, and DO-178B
attaches specific structural coverage objectives to different
certification levels this way: full @dfn{Statement Coverage} at level C,
@dfn{Decision Coverage} at level B and @dfn{Modified Condition/Decision
Coverage} at level A.

Below is an illustration of the principal differences between the
criteria over a simple example function out of an early version of the
Explore sources:

@smallexample

   --  Whether execution of CTRL by Robot R is unsafe

   function Unsafe
     (Ctrl : Robot_Control; R : Robot_Access) return Boolean
   is
      Situ : Situation;
   begin
      --  Probe the current situation in SITU and evaluate.
      --  Start by assuming CTRL is safe and adjust.

      Devices.Probe (Situ, R.H.DH);
      declare
         Is_Unsafe : Boolean := False;
      begin
         --  Stepping ahead into a rock block or a water pit is unsafe

         if Ctrl.Code = Step_Forward
            and then (Situ.Sqa = Block or else Situ.Sqa = Water)
         then
            Is_Unsafe := True;
         end if;

         return Is_Unsafe;
      end;
   end;
@end smallexample

Statement Coverage of the @code{Unsafe} function requires execution of
all the source statements at least once.
@c
This can be achieved with a single call to the function, as soon as the
boolean decision controlling the @code{if} statement evaluates to
@code{True}.

Decision Coverage requires that every decision has evaluated at least
once to @code{True} and at least once @code{False}, which necessitates
at least two calls in our example to exercise the @code{if} controlling
expression both ways.
@c
It also requires going through every possible entry and exit point,
without further impact of note on the simple example at hand.

Modified Condition/Decision Coverage requires additional variations over
the conditions, and combinations to show that each condition can affect
the decision outcome in an independent manner.
@c
This is expected to be possible with Nconditions+1 evaluations, so
enforces a more precise testing of the expressions structure while
keeping the test base complexity linear with the number of conditions.
@c
While this general principe always holds, there exist several variants
of the MCDC criteria, with differences in the way independence may be
shown.

@subsection Source vs Object Quantifiers
@noindent
Object and Source coverage quantifiers are of very different natures.
@c
Both have both pros and cons, some very dependent on the evaluation
context and purpose.

An interesting study is that of the implication relationships between
criteria, to determine if satisfying one criteria may be used as a means
to claim another.
@c
These correlations are not at all trivial in the general case.
@c
Below are a few points to illustrate.

As a starter example, we may consider that Object Branch or even
Instruction Coverage implies Statement Coverage while the opposite is
not true.
@c
To illustrate the basic idea, take the case of a modulo computation: it
is expressed with a single statement in C or Ada, and the machine code
typically features different paths to honor variations conditioned on
the sign of the operands.
@c
A single pass trough this code will cover the source statement and not
the full instruction set.
@c
Conversely, covering the full set of machine instructions necessitates
several passes through the code, hence coverage of the source statement.
@c
For the general case, statements for which no machine code is produced
need care but don't introduce fundamental difficulties.

Along similar lines, we may consider that full Object Branch Coverage
implies Decision Coverage while the opposite is not true.
@c
We also observe that Object Instruction Coverage does not imply Decision
Coverage.

Finally, it is established that Object Branch Coverage does not always
imply MC/DC in the general case @bibref{AR07/20}.
@c
It only does when a number of conditions hold together, such as:
@c
1/ the only boolean binary operators in use are those with short-circuit
semantics (@code{and then} and @code{or else} in Ada),
@c
2/ Different binary boolean operators are never mixed in the same
expression, and
@c
3/ the machine code features one conditional branch instruction per
condition.

In any case, assumptions validity need to be complemented with practical
consequences in industrial applications.
@c
In particular, using one criteria as a means to achieve another when an
implication holds (e.g. seeking OBC to achieve DC) might call for
unrequired significant additional testing efforts.

@c *******************************************************************
@c *                        XCOV FUNDAMENTALS                        *
@c *******************************************************************

@node xcov-grounds,xcov-guide,scov-basics,Top
@chapter Xcov Fundamentals

@section Instrumentation mode
@noindent
The core principle in the Xcov framework is to leverage the generation
of raw coverage data by a virtual execution environment instrumented to
produce machine level traces about the code it executes.

The environment typically is a representative emulator of a real
target microprocessor, possibly augmented with extensions to let it
communicate with external devices.
@c
For common architectures, we leverage @qemu{} @bibref{qemu} for this
purpose, as a reliable and efficient free-software emulator we can
instrument to generate the traces.

The environment may also be a pure virtual machine such as existing ones
for Java or Caml like languages.
@c
In any case, the program itself isn't instrumented, so coverage
measurements can be performed on target code, as embedded eventually,
and the virtual environment runs on development hosts, which offers a
lot of flexibility.

The raw coverage data out of the execution environment is very low level
information about the executed instruction and branch sequences at the
machine level.
@c
The actual contents structure may vary, depending on the kind of
analysis anticipated.

@section Object Coverage Analysis
@noindent
To start with, Xcov allows the confrontation of execution traces with
the full machine code available from program files, hence precise object
coverage analysis with both instruction and branch coverage capabilities.
@c
This is achievable with simple traces that can be gathered and
represented in a very efficient manner, schematically as a flat compact
map of status per executed instruction or linear sequence.

The results may first be rendered at the assembly language level, with
annotations for each machine instruction to indicate whether it was
executed or not, and for each conditional branch whether it has been
taken, not taken or both.

Then, provided extra information to establish instruction to source line
correspondance, Xcov is also able to render the object coverage outcome
through source annotations, with source line annnotations derived from
those of all the associated machine instructions.
@c
Typically, a source line is marked as @dfn{fully}/@dfn{partially}
covered when all/part of the associated machine instructions were
executed, and the instruction/line correspondance is extracted from
standard DWARF debug information or alike.

@section Source Coverage Analysis
@noindent
Xcov is also designed to allow Source Coverage Analysis, with central
focus on user source code and support for the three DO-178B criteria:
Statement, Decision and Modified Condition/Decision Coverage.
@c
For MCDC, the framework sets up the necessary elements to be able to
reconstruct the exercised run-time condition/decision vectors.
@c
An important part is the introduction of @dfn{Source Coverage
Obligations}, or SCOs, compact tables generated to indicate the source
elements of relevance to coverage analysis activities.
@c
SCOs are designed to be independent from the target certification level,
which only influences the way a given trace is determined to meet.

For @qemu{} targets and the @gcc{} compilation toochain, the toolset uses SCOs
and precise debug information to associate conditional branches with
conditions, then traces are extended to track the history of run-time
behavior at those branch points.
@c
Indeed, the object coverage flat execution traces aren't precise enough
in this case unless very strong constraints are met by the source
constructs.
@c
Using extended traces or flat ones with source constraints, the MCDC
capabilities of Xcov rely on the presence of a conditional branch
instruction for each non-constant condition.
@c
We provide sets of compilation options suitable for both this
particular purpose and for the Source Coverage analysis activity in
general.

@section Modularity and Flexibility
@noindent
Different teams have different organizations and software development
infrastructures.
@c
Xcov is designed as a modular set of light tools, intended to be
adaptable to various operational contexts.

@c *******************************************************************
@c *                          USER'S GUIDE                           *
@c *******************************************************************
@node xcov-guide,,xcov-grounds,Top

@chapter Xcov User's Guide

@section Getting Started
@noindent
Below is a verbatim copy of the distribution @code{README} file, which
provides a brief description of the package contents, installation
instructions and a Quick Start section, basic introduction to the
toolset architecture and interface:

@smallexample
@verbatiminclude README
@end smallexample

As suggested by the previous introduction, Xcov offers a front-end to
various coverage analysis related functionalities, each activated by a
toplevel of command line option:

@itemize @bullet
@item @option{run} ;
run code within an instrumented environment to produce execution traces.
@item @option{coverage} ;
process execution traces to produce user-level results.
@end itemize

The following sections provide further details on the various modes of
operation, first for simple cases where a single trace is to be produced
and analyzed, then for more sophisticated needs requiring coverage data
capitalization and consolidation.

@page
@section Instrumented Execution
@pindex xcov run
@noindent
@xrun{} offers a unified interface to launch programs for a specific
target machine within the appropriate instrumented execution environment
to produce execution traces.

The Quick Start example in the distribution @code{README} illustrates a
simple use for a @code{powerpc-elf} target, using the dedicated @gcc{}
toolchain to build from sources and the @option{--target} execution
engine selector.
@c
The general interface synopsis is available from @command{xcov --help},
as follows:

@smallexample

 run [OPTIONS] FILE [-eargs EARGS...]
   Options are:
   -t TARGET  --target=TARGET   Set the target
     targets: powerpc-elf leon-elf i386-pok i386-linux prepare
   -v --verbose                 Be verbose
   -T TAG  --tag=TAG            Put TAG in tracefile
   -o FILE  --output=FILE       Write traces to FILE
   -eargs EARGS                 Pass EARGS to the simulator

@end smallexample

@option{-v} requests verbose output, in particular the commands to run
the program within the underlying instrumented environment.

The @code{FILE} argument is the executable program file name.
@c
This name is stored as-provided in the output trace header, where it is
retrieved later for analysis purposes.

By default, @xrun{} writes the execution trace in the current directory,
in a file named like the executable input with a @code{.trace} suffix.
@c
For example @xrun{} @code{/path/to/myexecfile} produces a
@code{myexecfile.trace} file in the current directory.
@c
@option{--output} allows the selection of an alternate output file name.

@pindex @code{Trace tags}
The @option{--tag} option expects a string argument and stores it
verbatim as a trace tag attribute in the output trace header.
@c
The tag so associated with a trace can be retrieved from trace dumps
and is output as part of some analysis reports.
@c
It is useful as a flexible trace identification facility, structured as
users see fit for custom trace management purposes.

@page
@section Object Coverage Analysis
@pindex @code{xcov coverage}, for object coverage analysis
@noindent
Over execution traces, various levels of object coverage analysis may be
performed with @code{xcov coverage}.
@c
An analysis variant first needs to be selected with the @option{--level}
option:

@multitable @columnfractions .15 .8
@item @command{=insn}
@tab requests @dfn{Object Instruction Coverage} data, with an indication for
every instruction of whether it has been executed or not.

@item @command{=branch}
@tab requests @dfn{Object Branch Coverage} data, with extra details about
the directions taken by conditional branch instructions.

@end multitable

@noindent
An additional @option{--annotate} option selects the output format:

@multitable @columnfractions .15 .8
@item @command{=asm}
@tab annotated assembly code on standard output.

@item @command{=xcov[+]}
@tab annotated source files, with the object code for each source
line interspersed if the @code{+} variant is selected.

@item @command{=html[+]}
@tab html index of per source file coverage summary, with links to
annotated sources [@code{+} code expandable from each source line].

@item @command{=report}
@tab synthetic report of per subprogram coverage results.
@end multitable

@noindent
The following sections provides extra details and examples for each
situation.
@c
In principle, this is all pretty independent of the program
compilation options.
@c
Aggressive optimizations very often make source to object code
associations more difficult, however.
@c
Besides, if source coverage analysis is to be performed as well, the
whole process is simpler if the same compilation options are used, and
these have to be strictly controlled for source coverage.

@subsection Machine level reports, @code{--annotate=asm}
@noindent
For object coverage analysis purposes, @option{--annotate=asm} produces
annotated assembly code for all the program routines on standard output.
@c
The annotations are visible as a special character at the beginning of
each machine code line to convey information about the corresponding
instruction, with variants for instruction or branch coverage modes.
@c
We call @dfn{simple} those machine instructions which are not
@dfn{conditional branch} instructions.

@*
@noindent
For @dfn{Object Instruction Coverage}, with @option{--level=insn}, we
define:

@multitable @columnfractions .1 .8
@item @h{Note} @tab @h{Means ...}
@item '-'
@tab instruction was never executed
@item '+'
@tab instruction was executed
@end multitable

@*@noindent For @dfn{Object Branch coverage} (@option{--level=branch}),
the `+' case is refined for conditional branch instructions and two
additional notes are possible:

@multitable @columnfractions .1 .8
@item @h{Note} @tab @h{Means ...}
@item '-'
@tab instruction never was executed
@item '+'
@tab instruction was executed, taken both ways for a conditional
     branch
@item '>'
@tab conditional branch was executed, always taken
@item 'v'
@tab conditional branch was executed, never taken
@end multitable

@*@noindent
We qualify instructions marked with @option{+} as @dfn{fully covered},
those marked with @option{-} as @dfn{uncovered} and the others as
@dfn{partially covered}.

To illustrate, we will consider the Branch Coverage outcome for a piece
of the Explore example, produced out of a couple of runs within @qemu{} for
the PowerPC architecture.
@c
The original source of interest is the @code{if} statement which
controls the Station processing termination, upon a Quit request
from the user.
@c
The control is performed by a single decision, composed by two connected
conditions to expose a case insensitive interface:

@smallexample

   procedure Run (Sta : Station_Access) is
      ...
      Put ("'P'robe, 'S'tep, Rotate 'L'eft/'R'ight, 'Q'uit ? ");
      Flush;
      Get (C);

      if C = 'Q' or else C = 'q' then
         Kill (Sta.all);
         return;
      else
      ...

@end smallexample

We first run a sample session to exercise Probe, then Quit with 'Q',
and request branch coverage data in assembly format:

@smallexample

... $ xcov run --target=powerpc-elf explore
[Explore runs in @qemu{} - type 'p', then 'Q']

... $ xcov coverage --level=branch --annotate=asm explore.trace      

@end smallexample

For the code associated with the source bits of interest, this yields
the following assembly coverage report excerpt:

@smallexample
...
<stations__run>:
...
fffc1c0c +:     4b ff e6 7d   bl     0xfffc0288 <text_io__get>
fffc1c10 +:     2f 83 00 51   cmpiw  cr7,r3,0x0051
fffc1c14 +:     41 9e 00 0c   @b{beq-}   cr7,0xfffc1c20 <stations__run+00000078>
fffc1c18 +:     2f 83 00 71   cmpiw  cr7,r3,0x0071
fffc1c1c >:     40 9e 00 10   @b{bne-}   cr7,0xfffc1c2c <stations__run+00000084>
fffc1c20 +:     7f e3 fb 78   or     r3,r31,r31
fffc1c24 +:     4b ff e7 d1   bl     0xfffc03f4 <actors__kill>
...
@end smallexample

The @code{beq} and @code{bne} instructions are two conditional branches
corresponding to the two conditions.
@c
In addition to straightforward coverage of the rest of the code, the '+'
for the first branch indicates that it is fully covered and the '>' for
the second branch indicates partial coverage only.
@c
Indeed, both conditions were evaluated to False on the 'p' input, then
on 'Q' the first condition was evaluated to True and the second one was
short-circuited.

We run a second experiment, when the user quits with 'Q' immediatly.
@c
We observe that the first conditional branch is only partially covered
and the second one is not even exercised:

@smallexample
...
<stations__run>:
...
fffc1c0c +:     4b ff e6 7d   bl     0xfffc0288 <text_io__get>
fffc1c10 +:     2f 83 00 51   cmpiw  cr7,r3,0x0051
fffc1c14 >:     41 9e 00 0c   beq-   cr7,0xfffc1c20 <stations__run+00000078>
fffc1c18 -:     2f 83 00 71   cmpiw  cr7,r3,0x0071
fffc1c1c -:     40 9e 00 10   bne-   cr7,0xfffc1c2c <stations__run+00000084>
fffc1c20 +:     7f e3 fb 78   or     r3,r31,r31
fffc1c24 +:     4b ff e7 d1   bl     0xfffc03f4 <actors__kill>
...
@end smallexample

@subsection In-Source text reports, @code{--annotate=xcov[+]}
@noindent
For object coverage analysis purposes, @option{--annotate=xcov} produces
annotated source files with the @code{.xcov} extension in the current
directory, one per original compilation unit.
@c
The annotations are visible as a special character at the beginning of
every source line, which synthesizes the coverage status of all the
machine instructions generated for this line.
@c
The machine instructions are printed next to their associated source
line when the @option{+} option extension is used.

Eventhough the annotations are rendered on source lines in this case,
they are really meant to convey object code properties, hence are of a
different nature than what the DO-178B structural coverage criteria
refer to.

We defined a uniform synthesis of source line from object code
annotations for both instruction and branch coverage:

@multitable @columnfractions .1 .8
@item @h{Note} @tab @h{Means ...}
@item '.'
@tab no associated machine code for this line
@item '-'
@tab all the instructions associated with the line are '-' (uncovered)
@item '+'
@tab all the instructions associated with the line are '+' (fully covered)
@item '!'
@tab otherwise
@end multitable

To lines with associated object code we apply qualifiers similar to
those for individual instructions: '-', '+' and '!' denote
@dfn{uncovered}, @dfn{fully covered} or @dfn{partially covered} lines
respectively.

At this stage, @xcov{} relies on dwarf debug information to associate
machine instructions with their corresponding source lines, so these
annotations are only possible when this is available.
@c
In @gcc{} parlance, this requires compilation with the @option{-g}
command line switch, designed never to influence the generated code.

@subsection In-Source html reports, @code{--annotate=html[+]}
@noindent
For object coverage analysis purposes, @option{--annotate=html} produces
one @code{.html} browsable annotated source file per original
compilation unit in the current directory, with annotations identical to
the @option{=xcov} ones.
@c
Each source line is colorized to reflect its associated object code
coverage completeness, with green, orange and red for full, partial or
null coverage respectively.

An @code{index.html} page summarizes the coverage results and provide
links to the annotated sources.
@c
With the @code{+} extension, the annotated machine code for each line
may be expanded below it by a mouse click on the line.

@subsection Synthetic reports, @code{--annotate=report}
@noindent
For object coverage analysis purposes, @option{--annotate=report}
produces a synthetic summary of per function coverage results, with a
single annotation assigned to each function in the same way it is to
each source line in the @option{=xcov} or @option{'=html'} cases.

@subsection Inlined and Template/Generic entities
@noindent
The generated code for an inlined subprogram or a generic instantiation
implicitely associates with two source locations: the entity source
itself (what code materializes) and where the instantiation takes place
(where the generated code goes).
@c
Choices were made for In-Source reports.
@c
Behind the scenes, xcov uses standard debug information to establish the
links between object code and original source, so the choice stems from
this information essentially.
@c
The next paragraphs are specific to the @gnat{}/@gcc{} chains in this
respect.

For inlined calls, the @gcc{} debug information associates the generated
machine code with the inlined source positions, so the related object
coverage information is reported there.
@c
This scheme has all the instances reported at a centralized location and
allows use of the full inlined subprogram source structure to organize
the results.
@c
Consider for example the following excerpt of branch coverage report for
the Station control code in Explore.
@c
A call to an @code{Update} subprogram is inlined in
@code{Process_Pending_Inputs}.
@c
We observe that the code reported in the @code{Update} sources is coming
from the @code{process_pending_inputs} symbol, where it was inlined, and
that absence of code is reported at the call site, since indeed all the
code for this call is attached to the inlined entity.

@smallexample

  53 .:       procedure Update (Map : in out Geomap; Situ : Situation) is
  54 +:          Posa : constant Position := Pos_Ahead_Of (Situ);
<stations__run__process_pending_inputs.1939+fffc1bb4>:+
fffc1c04 +:  4b ff ed c1  bl     0xfffc09c4 <geomaps__pos_ahead_of>
fffc1c08 +:  90 61 00 30  stw    r3,0x0030(r1)
  55 .:       begin
  56 +:          Map (Posa.X, Posa.Y) := Situ.Sqa;
<stations__run__process_pending_inputs.1939+fffc1bc4>:+
fffc1c28 +:  88 01 00 19  lbz    r0,0x0019(r1)
fffc1c2c +:  98 03 00 0f  stb    r0,0x000f(r3)
  [...]
  63 +:       procedure Process_Pending_Inputs (Sta : Station_Access) is
  [...]
  68 .:             Update (Sta.Map, Situ);
@end smallexample

Similar principles apply to template instantiations such as those of Ada
generic units, and the centralized view property is well illustrated
this way.
@c
The excerpt below provides an example with the @code{Queues} abstraction
in Explore, instantiated in several places.
@c
The corresponding code sequences are all attached to original unit
source, with an indication of their instantiation locations via the
symbol names in the start-of-sequence addresses:

@smallexample

  39 +:    function Empty (Q : Queue) return Boolean is
<robot_control_links__data_queue_p__empty+fffc02fc>:+
fffc02fc +:  94 21 ff f0  stwu   r1,-0x0010(r1)
 [...]
<geomaps__situation_links__data_queue_p__empty+fffc0878>:+
fffc0878 +:  94 21 ff f0  stwu   r1,-0x0010(r1)
 [...]
@end smallexample

@subsection Focusing on subprograms of interest
@noindent
Xcov provides a number of facilities to allow filtering results so that
only those of actual interest show up.

The primary filtering device for object coverage analysis is the
@option{--routines} option to @code{xcov coverage}.
@c
@option{--routines} expects a single argument, to designate a set of
symbols, and restricts coverage results to machine code generated for
this set.
@c
The argument is either a single symbol name or the name of a file
prefixed with a @code{@@} character, expected to contain a list of
symbol names.

To illustrate, the example command below produces a branch coverage
report for the @code{Unsafe} subprogram part of the @code{Robots} unit
in Explore.
@c
Out of a @gnat{} compiler, the corresponding object symbol name is
@code{robots__unsafe}, here designated by way of a single entry in a
symbol list file:

@smallexample
$ cat slist
robots__unsafe

$ xcov coverage --level=branch --annotate=asm --routines=@@slist explore.trace
Coverage level: BRANCH
robots__unsafe !: fffc1074-fffc109b
fffc1074 +:  2f 83 00 02      cmpiw  cr7,r3,0x0002
fffc1078 +:  40 be 00 1c      bne+   cr7,0xfffc1094 <robots__unsafe+00000020>
[...]
@end smallexample

Xcov provides a @option{disp-routines} command to help the elaboration
of symbol lists.
@c
The general synopsis is as follows:

@smallexample
@verbatim
 disp-routines {[--exclude|--include] FILES}
   Build a list of routines from object files
@end verbatim
@end smallexample

@code{xcov disp-routines} outputs the list of symbols in a set built
from object files provided on the command line.
@c
'Object file' is to be taken in the general sense of 'conforming to a
supported object file format, such as ELF', so includes executable files
as well as single compilation unit objects.

The output set is built incrementally while processing the arguments
left to right.
@c
@option{--include} states ``from now on, symbols defined in the
forthcoming object files are to be added to the result set''.
@c
@option{--exclude} states ``from now on, symbols defined in the
forthcoming object files are to be removed from the result set''.
@c
An implicit @code{--include} is assumed right at the beginning, and each
object file argument may actually be an @code{@@}file containing a list
of object files.
@c
Below are a few examples of commands together with a description of the
set they build.
@c

@smallexample

$ xcov disp-routines explore
  # (symbols defined in the 'explore' executable)

$ xcov disp-routines explore --exclude test_stations.o
  # (symbols from the 'explore' executable)
  # - (symbols from the 'test_stations.o' object file)

$ xcov disp-routines --include @@sl1 --exclude @@sl2 --include @@sl3
  # (symbols from the object files listed in text file sl1)
  # - (symbols from the object files listed in text file sl2)
  # + (symbols from the object files listed in text file sl3)

@end smallexample

In-source reports, when requested, are generated for sources associated
with the selected symbols' object code via debug line information.
@c
Coverage synthesis notes are produced only on those designated lines.
@c
For example, @code{--annotate=xcov --routines=robots__unsafe} will
produce a single @code{robots.adb.xcov} in-source report with
annotations on the @code{Unsafe} function lines only, because the debug
info maps the code of the unique symbol of interest there and only there.

Note that inlining can have surprising effects in this context, when the
machine code is associated with the inlined entity and not the call
site.
@c
When the code for a symbol A in unit Ua embeds code inlined from unit
Ub, an in-source report for routine A only will typically produce two
output files, one for Ua where the source of some of the symbol code
reside, and one for Ub, for lines referenced by the machine code inlined
in A.   

@page
@section Source Coverage Analysis
@pindex @code{xcov coverage}, for source coverage analysis

Source coverage analysis focuses on source elements such as
``statements'' or ``decisions''.
@c
Machine object code is entirely abstracted away.
@c
For source coverage assessment, @xcov{} relies on @dfn{Source Coverage
Obligation} (SCO) tables, compact descriptions of the source elements
relevant to coverage analysis.

As of today, @xcov{} supports SCOs provided as part of the Ada Library
Information files generated by the @gnat{} compilers when invoked with
the @option{-gnateS} command line option.
@c
To obtain accurate results, the code should be compiled with
optimizers disabled (@command{-O0} in gcc parlance).
@c
Support for optimized code is being worked on for future versions.

The general process to perform source coverage analysis is similar to
the one for object coverage: @xrun{} produces execution traces, and
@code{xcov coverage} generates reports out of them. 
@c
Source coverage analysis is requested thanks to variants of the
@code{--level} option, which should be passed to both @xrun{} and
@code{xcov coverage}.

The set of SCOs for which coverage is to be assessed is provided by
way of a @option{--scos} command line option, which accepts either a
single @code{.ali} filename argument, or an @code{@@} prefixed
filename containing a list of @code{ali} files.
@c
@code{--scos} is the source oriented version of what @code{--routines}
offers in the object coverage case.
@c
They may not be used together.
@c
@code{--scos} conveys both SCO information to the analysis engine and
the selection of units for which result reports are to be produced.
@c
The option may be repeated on the command line, with cumulative
effects.

Source coverage results may be produced in several output formats,
selected with the @option{--annotate} command line option.
@c
@code{xcov}, @code{html}, and @code{report} are available, with
general characteristics identical to those described in the object
coverage section:
@c
@code{xcov} is a text format with a coverage annotation on each source
line, @code{html} features line colorization and an index page, and
@code{report} outputs the sequence of incomplete coverage diagnostics
out of the analysis performed.

@subsection Statement Coverage (SC)
@pindex @code{Statement Coverage}

Statement coverage is achieved with @code{--level=stmt}, together with
@code{--scos} to provide the set of SCOs of interest via ALI files.
@c
The @code{xcov} and @code{html} annotation formats both generate a
representation of the sources with annotations on each relevant line,
according to the following table:

@multitable @columnfractions .1 .8
@item @h{Note} @tab @h{Means ...}
@item '.'
@tab no SCO or no executable code for this line
@item '-'
@tab statement uncovered (not executed) on this line
@item '+'
@tab statement covered (executed) on this line
@end multitable

Below is a sample session to illustrate on the Explore example, for
the @code{robots} unit after recompilation with @option{-gnateS -O0}.
@c
Note the @option{--level} option passed to both @code{run} and
@code{coverage} invocations:

@smallexample

$ xcov run --level=stmt explore
... run session, trace goes to explore.trace by default ...

$ xcov coverage --level=stmt --scos=obj/robots.ali --annotate=xcov explore.trace

@end smallexample

To analyze a full set of units at once, just fetch the list of ALI files in
a list and provide an @code{@@}file to @code{--scos}.
@c
For instance, in a Unix-like environment:

@smallexample

$ ls obj/*.ali > alis
$ xcov coverage --scos=@@alis --level=stmt --annotate=xcov explore.trace

@end smallexample

@noindent
For the @code{Stations} unit, this produces a @code{stations.adb.xcov}
output like:

@smallexample

.../couverture/tools/xcov/examples/explore/src/stations.adb:

Coverage level: STMT
87% of 38 lines covered

[...]
  74 .:       function Control_For (C : Character) return Robot_Control;
  75 .:       --  Map user input character C to Robot_Control command, Nop if
  76 .:       --  the input isn't recognized.
  77 .:
  78 .:       function Control_For
  79 .:         (C : Character) return Robot_Control is
  80 .:       begin
  81 +:          case C is
  82 .:             when 'p' | 'P' =>
  83 +:                return (Code => Probe, Value => 0);
  84 .:             when 's' | 'S' =>
  85 +:                return (Code => Step_Forward, Value => 0);
  86 .:             when 'l' | 'L' =>
  87 -:                return (Code => Rotate_Left, Value => 0);
  88 .:             when 'r' | 'R' =>
  89 -:                return (Code => Rotate_Right, Value => 0);
[...]

@end smallexample

@noindent
@code{--annotate=report} simply diagnoses the set of source lines with
uncovered statements:

@smallexample

[...]
stations.adb:87: statement not covered
stations.adb:89: statement not covered
[...]

@end smallexample

@subsection Decision Coverage (DC)
@noindent
@xcov{} offers Decision Coverage assessment capabilities with
@option{--level=stmt+decision}.
@c
The use process is identical to the one for statement coverage, except
that it yields coverage results of a different nature.
@c
We refer to @dfn{decisions} as all the boolean expressions used to
influence the control flow via explicit constructs in the source
program (such as @code{if} statements or @code{while} loops), plus all
the boolean expressions that feature a short circuit operator in other
contexts (e.g. on the right hand side of an assignment).

A decision is said fully covered when tests were made so that the
decision has evaluated to both True and False.
@c
If only one of these two possible outcomes was exercized, the decision
is said partially covered.
@c
The case where none of the possible decision outcomes was exercized
corresponds to situations where the enclosing statement was not
exercized at all.
@c
Uncovered statements remain reported as such, without further details
even if there are decisions therein.

@noindent
The @code{xcov} and @code{html} annotation formats both generate a
representation of the sources with annotations at the beginning of
each relevant line, according to the following table:

@multitable @columnfractions .1 .8
@item @h{Note} @tab @h{Means ...}
@item '.'
@tab no SCO or no executable code for this line
@item '-'
@tab statement uncovered on this line
@item '!'
@tab decision partially covered on this line
@item '+'
@tab all the decisions on this line are fully covered
@end multitable

As for object coverage, additional information is available on request
with an extra @code{+} suffix on the annotation format, that is, with
@code{--annotate=xcov+} or @code{html+}.
@c
Extra details are typically provided for decisions partially covered,
with information about which outcome was not exercized.

The @code{--annotate=report} output lists information about uncovered
statements and partial decision coverage.
@c
For example, after exercizing Explore to have the robot execute safe
commands in both Cautious and Dumb modes, we get the expected results
below on a sample of the @code{Robots} control code:

@smallexample

  $ xcov coverage --level=stmt+decision --annotate=report
    --scos=obj/powerpc-elf/robots.ali explore.trace
  ...
  robots.adb:56:9: DECISION: outcome TRUE never exercised
  robots.adb:75:10: DECISION: outcome TRUE never exercised
  robots.adb:78: statement not covered

@end smallexample

For decision related diagnostics, the source location features both a
line and a column number to designate the first token of the decision
unambiguously.
@c
Below is the corresponding @code{--annotate=xcov+} output excerpt.
@c
Decision diagnostics are always expanded on the first line of the
decision:

@smallexample

  [...]
  51 .:    function Unsafe (Cmd : Robot_Command; Sqa : Square) ...
  52 .:    begin
  53 .:       --  Stepping forward with a block or a water pit ahead is Unsafe
  54 .:
  55 +:       return
  56 !:         Cmd = Step_Forward
DECISION "Cmd = Ste..." at 56:9: outcome TRUE never exercised
  57 !:         and then (Sqa = Block or else Sqa = Water);
  58 .:    end Unsafe;
  [...]
  64 .:    procedure Process_Next_Control
  65 .:      (Port : Robot_Control_Links.IOport_Access)
  66 .:    is
  [...]
  73 .:       --  Cautious, the robot refuses to process unsafe controls
  74 .:
  75 !:       if Robot.Mode = Cautious
DECISION "Robot.Mod..." at 75:10: outcome TRUE never exercised
  76 !:         and then Unsafe (Ctrl.Code, Probe_Ahead (Robot.Hw.Rad))
  77 .:       then
  78 -:          return;
  79 .:       end if;
  [...]

@end smallexample

@subsection Modified Condition/Decision Coverage (MCDC)
@noindent
In a similar fashion to statement or decision coverage, @xcov{} offers
Modified Condition/Decision Coverage assessment capabilities with
@option{--level=stmt+mcdc}.

Compared to Decision Coverage, MCDC processing incurs extra
verifications on the demonstration by the tests of the independent
influence of boolean atoms in decisions, called @dfn{conditions} in
the DO-178 literature.
@c
Several variants of the criterion apply in the field, with a common
idea: for each condition in a decision, the tests are required to
expose a pair of valuations where both the condition and the decision
value change while some extra property on the other conditions holds.

The point is basically to demonstrate that every condition is
significant in the decision and that sufficient tests were performed
to exercize representative combinations of the possible behaviors.
@c
An important aspect is to keep the number of required tests linear
with the number of conditions in a decision.
@c
All the variants of MCDC are expected to be satisfiable with
Nconditions+1 @dfn{vectors} of condition/decision values in regular
situations.

@dfn{Unique Cause MCDC} is a common variant where the extra property is
stated as ``all of the other conditions in the decision keep the same
value''.
@c
To illustrate, let us consider the case of @code{A and then B}, as a
single decision with two conditions @code{A} and @code{B}.
@c
The table below expands the 4 possible condition/decision vectors,
with T/F to represent the True/False boolean values and indications
about pairs demonstrating Unique Cause independent effect of each
condition (vectors #1 and #3 for @code{A}, #1 and #2 for @code{B}):

@multitable @columnfractions .05 .05 .05 .1 .05 .05
@item # @tab @code{A} @tab @code{B} @tab @code{A && B} @tab @tab
@item 1 @tab T @tab T @tab T @tab @code{A} @tab @code{B}
@item 2 @tab T @tab F @tab F @tab          @tab @code{B}
@item 3 @tab F @tab T @tab F @tab @code{A} @tab
@item 4 @tab F @tab F @tab F @tab   @tab
@end multitable

Xcov actually implements another common variant: @dfn{Masking MCDC},
with particular semantics for short-circuit operators.
@c
The idea is to accept variations of some of the extra conditions in an
independence pair as long as these conditions are not evaluated
(masked) due to short-circuit semantics.
@c
This variant provides additional flexibility on the set of tests
required to satisfy the criterion without reducing the minimal size of
this set.
@c
In the @code{and then} case, the effect is the possibility to use the
#4 + #1 pair as well to demonstrate the independent influence of
@code{A} on the decision.
@c
Indeed, @code{B} is not evaluated at all when @code{A} is False in
this expression, so changes on the value of @code{B} are irrelevant.

Output-wise, MCDC results materialize with as
@code{--annotate=report} diagnostics on conditions, identified with
their precise file:line:column source location.
@c
Using the same decision as in the previous example to illustrate, we
run the Explore robot in Cautious mode only, try both safe and unsafe
actions and get:

@smallexample

robots.adb:75:10: CONDITION: failed to show independent influence, MC/DC not achieved

@end smallexample

@noindent
Such condition related messages are only emitted when no more general
diagnostic applies on the associated decision or statement.
@c
In our familiar example, attempting only safe actions in Cautious mode
yields a ``outcome TRUE never exercised'' diagnostic, not a couple of
condition related messages.
@c
The in-source notes for the @code{xcov} or @code{html} formats are the
same as for decision coverage reports, with condition specific cases
marked with '!' as well.

@page
@section Advanced features

@subsection Coverage Data Capitalization & Consolidation
@c
The @xcov{} philosophy with respect to coverage data capitalization is
to provide flexible means to allow custom trace management facilities,
not to dictate a specific organization.
@c
Two devices were introduced for this purpose: trace tags let users
associate an arbitrary string with each execution trace, and
@xrun{} stores a reference to the executable program there as well.
@c
In addition to this, @xcov{} features coverage consolidation
capabilities, to allow coverage analysis of a provided set of routines
from runs exercising them possibly in the context of different
executable programs.

To illustrate, we analyze object branch coverage of the @code{Unsafe}
function of the Explore @code{Robots} unit.
@c
We first run a simple interactive session which exercises the function
only partially and look at the results:

@smallexample

$ xcov run --target=powerpc-elf --tag 'Safe explore session' explore
[... Probe, Step on clear square, Quit ...]

$ xcov coverage --level=branch --annotate=xcov+ --routines=robots__unsafe
  explore.trace  
   
  robots.adb.xcov
 [...]
  57 .:  function Unsafe (Cmd : Robot_Command; Sqa : Square) return Boolean is
  58 .:  begin
  59 .:     --  Stepping forward into a rock block or a water pit is Unsafe
  60 .:
  61 .:     return Cmd = Step_Forward
  62 !:       and then (Sqa = Block or else Sqa = Water);
<robots__unsafe>:
fffc13a4 +:  2f 83 00 02  cmpiw  cr7,r3,0x0002
fffc13a8 +:  40 be 00 1c  bne+   cr7,0xfffc13c4 <robots__unsafe+00000020>
fffc13ac +:  2f 84 00 01  cmpiw  cr7,r4,0x0001
fffc13b0 v:  41 9e 00 0c  beq-   cr7,0xfffc13bc <robots__unsafe+00000018>
fffc13b4 +:  2f 84 00 02  cmpiw  cr7,r4,0x0002
fffc13b8 >:  40 be 00 0c  bne+   cr7,0xfffc13c4 <robots__unsafe+00000020>
fffc13bc -:  38 60 00 01  li     r3,0x0001
fffc13c0 -:  4e 80 00 20  blr
fffc13c4 +:  38 60 00 00  li     r3,0x0000
@end smallexample

These results are as expected.
@c
The first branch is fully covered because the session featured both a
Probe and a Step forward, so the @code{Cmd = Step_Forward} condition
is exercised both ways.
@c
The two following branches are only partially covered because we never
actually try any of the unsafe steps forward.

We then run the provided unit tests in addition, combine the results
and observe full object branch coverage:

@smallexample
$ make UNIT_TESTS=test_explore
[...]
xcov run --target=powerpc-elf test_explore

$ xcov coverage --level=branch --annotate=xcov+ --routines=robots__unsafe
  test_explore.trace explore.trace


  robots.adb.xcov
  [...]
  57 .:   function Unsafe (Cmd : Robot_Command; Sqa : Square) return Boolean is
  58 .:   begin
  59 .:      --  Stepping forward into a rock block or a water pit is Unsafe
  60 .:
  61 .:      return Cmd = Step_Forward
  62 +:        and then (Sqa = Block or else Sqa = Water);
<robots__unsafe>:
fffc3b00 +:  2f 83 00 02  cmpiw  cr7,r3,0x0002
fffc3b04 +:  40 be 00 1c  bne+   cr7,0xfffc3b20 <robots__unsafe+00000020>
fffc3b08 +:  2f 84 00 01  cmpiw  cr7,r4,0x0001
fffc3b0c +:  41 9e 00 0c  beq-   cr7,0xfffc3b18 <robots__unsafe+00000018>
fffc3b10 +:  2f 84 00 02  cmpiw  cr7,r4,0x0002
fffc3b14 +:  40 be 00 0c  bne+   cr7,0xfffc3b20 <robots__unsafe+00000020>
fffc3b18 +:  38 60 00 01  li     r3,0x0001
fffc3b1c +:  4e 80 00 20  blr
fffc3b20 +:  38 60 00 00  li     r3,0x0000

@end smallexample

The example provided here focuses on object coverage analysis for
illustrative puroposes.
@c
Xcov's consolidation capabilities apply identically to the source
coverage analysis case, with multiple execution traces on input and
@code{--scos} to specify the sources subset of interest.

@subsection XML outputs for automated processing
@pindex @code{XML outputs}
In addition to the @code{report}, @code{xcov[+]} and @code{html[+]}
output formats, @xcov{} offers XML outputs for all the supported
criteria.
@c
These outputs are obtained with @option{--annotate=xml} on the command
line, which generates an XML file for each source file of interest,
plus an @code{index.xml} which includes all the others.

XML outputs are intended for automated processing by other tools, and
provide a representation of @xcov{} internal computations with full
details for maximum flexibility.
@c
Their specification is provided as an appendix of this document.

@chapter Appendices

@node explore,,Top,Top
@section The ``Explore'' Guide Example
@noindent
The Explore example is a toy Ada application we use throughout the @xcov{}
documentation to introduce and illustrate a number of concepts.
@c
Below is a short functional and organisational description, verbatim from
the sources:

@smallexample

@verbatiminclude examples/explore/src/overview.ads
@end smallexample

@page
@section Trace Format Definition

This information is best located and maintained in the source comments,
where it naturally gets updated as the project evolves.
@c
Below is a verbatim inclusion of the relevant Ada specification:

@smallexample
@verbatiminclude qemu_traces.ads
@end smallexample

@page
@section Source Coverage Obligations Definition

Below is a verbatim inclusion of the relevant Ada specification:

@smallexample
@verbatiminclude gnat/scos.ads
@end smallexample

@page
@section XML output specifications


@c *******************************************************************
@c *                          BIBLIOGRAPHY                           *
@c *******************************************************************

@chapter Bibliography

@macro CHILENSKI
John J. Chilenski
@end macro

@macro KURTZ
John L. Kurtz
@end macro

@macro MILLER
S. Miller
@end macro

@macro CAST
CAST, Certification Authorities Software Team
@end macro

@macro FAA
FAA, Federal Aviation Administration
@end macro

@macro bibdef{entry}
@anchor{\entry\}@strong{[\entry\]}
@end macro

@multitable @columnfractions .1 .8

@item @bibdef{gcc}
@tab GCC: The GNU Compiler Collection.
@c
http://gcc.gnu.org

@item @bibdef{qemu}
@tab QEMU, a Fast and Portable Dynamic Translator.
@c
Fabrice Bellard.
@c
Proceedings of the ``USENIX 2005 Annual Technical Conference, FREENIX
Track'', pp 41-46.
@c
http://bellard.org/qemu/

@item @bibdef {mctut}
@tab A Practical Tutorial on Modified Condition/Decision Coverage.
@c
@CHILENSKI{} et al.
@c
NASA/TM-2001-210876, 2001.

@item @bibdef {mcapp}
@tab Applicability of Modified Condition/Decision Coverage to
Software Testing.
@c
@CHILENSKI{} and @MILLER{}.
@c
IEEE Software Engineering Journal, volume 9, issue 5, September 2004.

@item @bibdef {cast6}
@tab Rationale for accepting Masking MCDC in certification projects.
@c
@CAST{}. Position Paper #6, August 2001.

@item @bibdef {cast10}
@tab What is a Decision in Application of Modified Condition/Decision
Coverage (MC/DC) and Decision Coverage (DC) ?
@c
@CAST{}. Position Paper #10, June 2002.

@item @bibdef {ar0118}
@tab An Investigation of Three Forms of the Modified
Condition/Decision Coverage (MCDC) Criterion.
@c
@CHILENSKI{}. DOT/FAA/AR-01/18, April 2001.

@item @bibdef {ar0654}
@tab Software Verification Tools Assessment Study.
@c
@FAA{}. DOT/FAA/AR-06/54, June 2007.

@item @bibdef {ar0720}
@tab Object Oriented Technology Verification Phase 3 Report -
Structural Coverage at the Source Code and Object Code Levels.
@c
@CHILENSKI{} and @KURTZ{}. DOT/FAA/AR-07/20, June 2007.

@item @bibdef {rcdc}
@tab From MC/DC to RC/DC: Formalization and Analysis of
Control-Flow Testing Criteria.
@c
S. Vilkomir and J. Bowen.
@c
ZB2002: Formal Specification and Development in Z and B, Springer LNCS
2272, 2002.

@end multitable

@chapter Index

@printindex pg

@bye
