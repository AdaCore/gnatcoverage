\input texinfo  @c -*-texinfo-*-

@c %**start of header
@c oooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo
@c                                                                            o
@c                            XCOV DOCUMENTATION                              o
@c                                                                            o
@c oooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo

@setfilename xcov.info
@settitle Xcov documentation
@c %**end of header

@macro xcov
@command{xcov}
@end macro

@macro bibref {entry}
[@cite{\entry\}]
@end macro

@c Directory where the Explore guide example is stored
@set explore_dir examples/explore

@titlepage
@title Xcov Fundamentals & Users Guide
@end titlepage

@contents

@c *******************************************************************
@c *                         ABOUT THIS DOCUMENT                     *
@c *******************************************************************

@node Top
@top  About this Document

@noindent
This document introduces the fundamentals of Xcov, a non intrusive
structural coverage analysis framework, together with a toolset user's
guide.

@ref{explore} presents a simple application example, support to
illustrate various points in the subsequent chapters.

@ref{scov-basics} introduces the contextual elements of the Xcov's
development: a general definition and rationale for ``Structural
Coverage Analysis'', the process model we consider, and then an
identification of different possible kinds of analysis activities.

@ref{xcov-grounds} describes the Xcov framework core operation mode and
capabilities.

@ref{xcov-guide} is the toolset user's guide, with details on the tools
command lines, use examples for various situations and outputs
interpretation guidelines.

@menu
* explore::      The Explore Guide Example
* scov-basics::  Structural Coverage Basics
* xcov-grounds:: Xcov Fundamentals
* xcov-guide::   Xcov User's Guide
@end menu


@c *******************************************************************
@c *                      COVERAGE ANALYSIS BASICS                   *
@c *******************************************************************

@node explore,scov-basics,Top,Top
@chapter The ``Explore'' Guide Example
@noindent
The Explore example is a toy Ada application we use throughout the Xcov
documentation to introduce and illustrate a number of concepts.
@c
Below is a short functional and organisational description, verbatim from
the sources:

@smallexample
@c @verbatiminclude @value{explore_dir}/overview.ads
@end smallexample

@node scov-basics,xcov-grounds,explore,Top
@chapter Structural Coverage Analysis Basics

@section General Definition & Rationale
@noindent
To a first approximation, structural coverage analysis may be viewed as
a software development activity aimed at analysing which pieces of an
application source and/or machine code are exercised by executions of
the application software.
@c
There may be several reasons why such an activity is performed and extra
details about what exactly is to be evaluated.

One of our target applications is the use of coverage analysis in
software certification processes such as the DO-178B standard enforced
in the civilian avionics domain.
@c
In this context, the application code and the test sequences are both
derived from a common set of requirements, independently, and structural
coverage analysis is one of the means to confront the pieces.
@c
Essentially, it allows an assessment of the testing campain quality and
helps the identification of various forms of pointless code or of
requirements imprecision/incompleteness,

In the following sections we introduce the elements of a coverage
analysis process together with @dfn{terms} to be reused throughout this
document.

@section Process Model

@subsection Primary Process Abstractions
@noindent
A typical coverage analysis elementary process comprises three principal
steps:
@enumerate
@item
A binary @dfn{executable program} is produced from a set of program
@dfn{sources} by development toolchains with compilers, linkers, etc.

@item
The executable program is run within an @dfn{execution environment}, and
this execution produces @dfn{raw coverage data} about paths it
exercises.

@item
The raw coverage data is interpreted or @dfn{mapped} into some user
readable representation.
@end enumerate

As an illustrative example, consider the common GCC/GCOV process, exactly
along those lines: the program is compiled and linked by GCC @bibref{gcc} 
with special command-line options, execution produces a binary data file
and the GCOV tool can then be used to generate annotated sources from
the original files, the executable and the execution data.
@c
Below is an example to illustrate for a simple test of the Explore queues
abstraction, compiled with the GNAT toolchain for Ada:

@smallexample
# Build with gcov related options - produces executable program

    $ gnatmake test_queues.adb -fprofile-arcs -ftest-coverage

# Run program - produces raw coverage data files (queues.gcda, ...)

    $ ./test_queues

# Map to user representation - produces annotated sources (queues.adb.gcov, ...)
 
    $ gcov test_queues
@end smallexample
  
The annotations are in the first column for each source line: @code{'-'}
indicates there is no associated object code, numbers indicates the
number of times code for this line was executed, and @code{'#'} signs
indicates object code never executed:

@smallexample

        [...]
        1:    9:procedure Test_Queues is
        -:   10:   package Integer_Queues is new Queues (Data_Type => Integer);
        -:   11:   use Integer_Queues;
        -:   12:
        -:   13:   X : Integer;
        1:   14:   Q : Integer_Queues.Queue (Capacity => 1);
        -:   15:begin
        1:   16:   Push (12, Q);
        1:   17:   Pop (X, Q);
        1:   18:   if X /= 12 then
    #####:   19:      raise Program_Error;
        -:   20:   end if;
        -:   21:end;

@end smallexample

In this excerpt, the never executed code is expected to show up this way,
as it is intended to trigger only when the test didn't behave as it should.
@c
This points at an important distinction to make: the @code{Test_Queues}
procedure in this example is @dfn{testing code} written to exercise
pieces of the @code{Queues} abstraction, and only the latter will be an
actual part of the application.
@c
Most of the time, we're only interested in the coverage results for such
@dfn{applicative} code.

The form of the raw information depends on the coverage analysis toolset
technology.
@c
This is most often binary data.
@c
The production of raw coverage data at run time always involves some
sort of @dfn{instrumentation} to have the execution produce information
it normally wouldn't produce.
@c
This may be achieved in several possible manners:
@itemize
@item @dfn{Source Instrumentation}:
The coverage analysis toolset adds explicit statements and data
structures to the program source to maintain the coverage state.
@c
This is what many commercial products do.

@item @dfn{Object Instrumentation}:
The development toolchain inserts extra machine state and instructions
in the program executable object code.
@c
This is the GCC/GCOV approach.

@item @dfn{Environment Instrumentation}:
The execution environment is setup to produce a trace of the program paths
taken at the machine instruction level, leaving the program code untouched.
@c
This is what solutions based on hardware probes or on instrumented
virtual execution environments do.

@end itemize

There are variants of each technique in the field, each with it's own set
of advantages and drawbacks compared to others.
@c
While the base process applies to many situations, refinements are
useful in some cases, as outlined in the following sections.

@subsection Coverage Data Capitalization
@noindent
Proper coverage of applicative code often requires several test
executions on possibly disjoint pieces of the final system, with each
test providing its own partial coverage outcome.
@c
@dfn{Capitalization} denotes the storage of the partial results and the
analysis framework capabilities to process the capitalized data.

Different tests could for instance be several executions of the same
program with behavior differences caused by external input variations.
@c
They could also be executions of different programs exercizing different
units of the applicative code or common applicative code with different
parameters.

Consider for instance a common data structure implementation such as
the bounded @code{Queues} Ada package in the Explore example.
@c
To honor a common requirement, it contains simple error handling code so
that an "Ada exception X is raised on attempts to extract an item out of an
empty queue", and we expect this code not to be exercised in regular
executions.
@c
It remains applicative code, still, and even the weakest DO-178B
certification level requires tests to cover it, to make sure that at least
minimal checks on its behavior with respect to requirements were performed.
@c
Something has to be done outside nominal executions in this case.
@c
One possibility is to construct a separate program dedicated to just
testing this abstraction, which would force an artificial queue underflow.
@c
Of course, the dedicated test program could well cover the whole package
on its own on such a simple example.

One-shot full coverage is generally not possible in more complex
situations, however, and the example shows it is already partially
impossible with only regular Explore executions.
@c
Besides, even if full coverage a some applicative components could
theortically be achieved from a single execution, it is often just more
convenient or sensible to be able to reach the goal in an incremental
fashion.
@c
In the Explore case, for instance, a strategy like "purpose is to maximize
the entire application coverage by running a minimal number of sessions"
would be a pain and actually go against the requirements based testing
philosophy.
@c
One instead typically runs different sessions to verify different
specific application requirements, each session produces it's own
coverage data, capitalized, and a capitalization-aware coverage analysis
toolset unifies these partial coverage results into a single view.

@subsection Coverage Data Consolidation
@noindent
Coverage of all the pieces of a final application is often not performed
with all the pieces integrated together.
@c
In complex systems, this integration is a delicate process, not possible
before late stages of the project, and it is often useful or simply
unavoidable to perform coverage analysis on segregated pieces first.
@c
@dfn{Consolidation} denotes the process of gathering the coverage
information for the various pieces of a system into a unified view, for
instance to check that proper coverage was achieved for all the pieces.
@c
Technically, consolidation can be viewed as a set of means to use a
generalized capitalization capability for all the pieces of a system.

The need for coverage data consolidation often correlates with testing
strategies: whether coverage data is obtained from unit testing of
individual components, from integration testing of the system as a whole,
from some intermediate organisation, or possibly from a mix of all these.
@c
Any of these could apply to the Explore example case.

@subsection Process Integration
@noindent
As hinted by the previous sections, coverage analysis is a potentially
complex activity, which requires potentially complex metrics on
potentially complex software involved in potentially complex project
development cycles.

@dfn{Process integration} refers to the organization of the analysis
toolset that will provide consistent and easy access to all the features
of interest for a given project.
@c
The toolset needs to be both powerful enough to provide the desired
functionalities and flexible enough to accomodate the various possible
project organizations in the field.

@section Coverage Analysis Classification
@noindent
We distinguish two broad classes of analysis activities: @dfn{source}
and @dfn{object} coverage analysis.
@c
The process always consists in the evaluation of various possible
@dfn{coverage quantifiers} such as ``which program statements were
covered/not-covered by this set of executions ?'' or ``What percentage
of the total source code do these values represent ?'', most often
driven by specific objectives.

Every toolset offers its own spectrum of analysis possibilities, with
variations in the implementation schemes behind the scene, in particular
regarding the instrumentation mode.

@subsection Object Coverage Analysis
@noindent
Object Coverage Analysis focuses on machine object code coverage,
with two essential quantifiers:

@itemize
@item @dfn{Object Instruction Coverage (OIC)},
a quantification of the program machine instructions exercised by a set
of program executions.

@item @dfn{Object Branch Coverage (OBC)},
OIC + a quantification of the directions taken by each machine
conditional branch instruction in the program as exercised by a set of
executions.
@end itemize

In both cases, results can be rendered on a representation of the
machine code (for instance an annotated assembly language output) or on
a representation of the program sources.
@c
The focus is always on machine code coverage, still, and source
annotations in this context are just a means to organize and hilight
machine code properties of interest for the end user.

@subsection Source Coverage Analysis
@noindent
Source Coverage Analysis focuses on user source code and simply
abstracts the machine code away.
@c
The DO-178B structural coverage criteria operate at this level, with
three quantifiers defined over three core elements:

@itemize
@item @dfn{Source statement},
just referred to in the usual programming language sense.

@item @dfn{Decision},
defined as ``a Boolean expression composed of conditions and zero or
more Boolean operators.''.

@item @dfn{Condition},
defined as ``a decision without a Boolean operator'' with an extra
detail: ``If a condition appears more than once in a decision, each
occurrence is a distinct condition.''.
@end itemize

@noindent Then we have:
@itemize
@item @dfn{Source Statement Coverage (SSC)},
a quantification of the source statements exercised by a set of
program executions.

@item @dfn{Source Decision Coverage (SDC)},
SSC + a quantification of the values taken by each logical decision and
of which entry/exit points were exercised by a set of program
executions.

@item @dfn{Source Modified Condition/Decision Coverage (SMCDC)},
SDC + a quantification of wich conditions took their two possible
outcome and which were shown to have independant effect on their
decisions out of a set of program executions.
@end itemize

The quantifier names are often used standalone to denote coverage
objectives, for instance ``achieving Source Statement Coverage'' denotes
covering 100% of the program source statements, and the ``source'' part
is often omitted and implicitly assumed.
@c
DO-178B attaches specific structural coverage objectives to different
certification levels this way, with @dfn{Statement Coverage} at level C,
@dfn{Decision Coverage} at level B and @dfn{Modified
Condition/Decision Coverage} at level A.

Below is an illustration of the principal differences between the
criteria over a simple example function out of an early version of the
Explore sources:

@smallexample

   --  Whether execution of CTRL by Robot R is unsafe

   function Unsafe
     (Ctrl : Robot_Control; R : Robot_Access) return Boolean
   is
      Situ : Situation;
   begin
      --  Probe the current situation in SITU and evaluate.
      --  Start by assuming CTRL is safe and adjust.

      Devices.Probe (Situ, R.H.DH);
      declare
         Is_Unsafe : Boolean := False;
      begin
         --  Stepping ahead into a rock block or a water pit is unsafe

         if Ctrl.Code = Step_Forward
            and then (Situ.Sqa = Block or else Situ.Sqa = Water)
         then
            Is_Unsafe := True;
         end if;

         return Is_Unsafe;
      end;
   end;
@end smallexample

Statement Coverage of the @code{Unsafe} function requires execution of
all the source statements at least once.
@c
This can be achieved with a single call to the function, as soon as the
boolean decision controlling the @code{if} statement evaluates to
@code{True}.

Decision Coverage requires that every decision has evaluated at least
once to @code{True} and at least once @code{False}, which necessitates
at least two calls in our example to exercise the @code{if} controlling
expression properly.
@c
It also requires going through every possible entry and exit point,
without further impact of note on the simple example at hand.

Modified Condition/Decision Coverage requires additional variations over
the conditions, and combinations to show that each condition can affect
the decision outcome in an independant manner.
@c
This is expected to be possible with Nconditions+1 evaluations, so
enforces a more precise testing of the expressions structure while
keeping the test base complexity linear with the number of conditions.
@c
While this general principe always holds, there exist several variants
of the MCDC criteria, with differences in the way independance may be
shown.

@subsection Source vs Object Quantifiers
@noindent
Object and Source quantifiers have both pros and cons, some very
dependent on the evaluation context and purpose.

An interesting and difficult question is that of the possible
equivalence of one criterion to another one, for some definition of
``equivalence'' to start with.
@c
For instance, it is established that OBC does not always imply MCDC in
the general case @bibref{AR07/20}.
@c
It only does when a number of conditions hold together, such as: 1/
the only boolean binary operators in use are those with short-circuit
semantics (@code{and then} and @code{or else} in Ada), 2/ Different
binary boolean operators are never mixed in the same expression, and
3/ the machine code features one conditional branch instruction per
condition.

Conversely, even when OBC implies some source criteria, it is
often too strong for this purpose.

[TO BE REFINED]

@c *******************************************************************
@c *                        XCOV FUNDAMENTALS                        *
@c *******************************************************************

@node xcov-grounds,xcov-guide,scov-basics,Top
@chapter Xcov Fundamentals

@section Instrumentation & Raw Coverage Data
@noindent
The core principle in the Xcov framework is to leverage the generation
of raw coverage data by a virtual execution environment instrumented to
produce machine level traces about the code it executes.

The environment typically is a representative emulator of a real
target microprocessor, possibly augmented with extensions to let it
communicate with external devices.
@c
For common architectures, we leverage Qemu @bibref{qemu} for this
purpose, as a reliable and efficient free-software emulator we can
instrument to generate the traces.

The environment may also be a pure virtual machine such as existing ones
for Java or Caml like languages.
@c
In any case, the program itself isn't instrumented, so coverage
measurements can be performed on target code, as embedded eventually,
and the virtual environment runs on development hosts, which offers a
lot of flexibility.

The raw coverage data out of the execution environment is very low level
information about the executed instruction and branch sequences at the
machine level.
@c
The actual contents structure may vary, depending on the kind of
analysis anticipated.

@section Object Coverage Analysis
@noindent
To start with, Xcov allows the confrontation of execution traces with
the full machine code available from program files, hence precise object
coverage analysis with both instruction and branch coverage capabilities.
@c
This is achievable with simple traces that can be gathered and
represented in a very efficient manner, schematically as a flat compact
map of status per executed instruction or linear sequence.

The results may first be rendered at the assembly language level, with
annotations for each machine instruction to indicate whether it was
executed or not, and for each conditional branch whether it has been
taken, not taken or both.

Then, provided extra information to establish instruction to source line
correspondance, Xcov is also able to render the object coverage outcome
through source annotations, with source line annnotations derived from
those of all the associated machine instructions.
@c
Typically, a source line is marked as @dfn{fully}/@dfn{partially}
covered when all/part of the associated machine instructions were
executed, and the instruction/line correspondance is extracted from
standard DWARF debug information or alike.

@section Source Coverage Analysis
@noindent
Xcov is also designed to allow Source Coverage Analysis, with central
focus on user source code and support for the three DO-178B criteria:
Statement, Decision and Modified Condition/Decision Coverage.
@c
For MCDC, the framework sets up the necessary elements to be able to
reconstruct the exercised run-time condition/decision vectors, without
ever modifying the program as other instrumentation techniques would do.

An important element for source coverage analysis with Xcov is the
introduction of @dfn{Source Coverage Obligations} (SCOs), compact tables
generated to indicate the source elements of relevance to coverage
analysis activities.
@c
SCOs are designed to be independant from the target certification level,
which only influences the way a given trace is determined to meet.

For Qemu targets and the GCC compilation toochain, the toolset uses SCOs
and precise debug information to associate conditional branches with
conditions, then traces are extended to track the history of run-time
behavior at those branch points.
@c
Indeed, the object coverage flat execution traces aren't precise enough
in this case unless very strong constraints are met by the source
constructs.

On the code generation front, using extended traces or flat ones with
source constraints, the MCDC capabilities of Xcov rely on the presence
of a conditional branch instruction for each non-constant condition.
@c
We provide a set of compilation options suitable for both this
particular purpose and for the Source Coverage analysis activity in
general.
@c
This set of options is designed to remain reasonable for production use,
so that source coverage analysis may be performed on the final code, as
embedded eventually.
@c
If the production code absolutely requires options incompatible with the
source coverage analysis process, the latter remains doable with its own
set of options and Xcov allows object coverage analysis on the final
bits in any case.

@c *******************************************************************
@c *                          USER'S GUIDE                           *
@c *******************************************************************
@node xcov-guide,,xcov-grounds,Top

@chapter Xcov User's Guide - Qemu/GCC edition

@section Getting Started

@subsection Package Contents

As of today, the Xcov framework comprises two core command line
components:

@itemize

@item
An instrumented version of Qemu, able to generate execution traces of
the machine code it executes, and

@item
The @xcov{} trace analyzer, able to decode the execution traces out of
Qemu into various user readable formats, text or html, some of which may
be visualized through GPS, the GNAT Programming Studio graphical IDE
(starting from version 4.3.0).

@end itemize

@noindent
The package also includes

@itemize
@item
A light Qemu Board Support Package to link with your executable to let
it run within the emulated environment,

@item
A couple of low level components for Ada (simple IO, memory block
copy/set/compare services, ...) in case they are not included in your
run-time library

@item
A number of example programs you can exercise to get familiar with the
toolset capabilities and which we'll use throughout the rest of this
document,

@item
A support @code{Makefile} to automate an illustrative build/run/analyze
sequence for the examples.

@end itemize

@subsection Quick Start

We will start by running one of the provided examples thanks to the
support @code{Makefile}, assuming you have both your target compilation
toolchain and the Xcov package installed.

The first step is to setup the @code{PATH} environment variable to
include locations for both the target compiler and the Xcov @samp{bin}
directory.
@c
For example with a @code{bash} like shell:

@smallexample
$ PATH=/usr/local/gnatpro/6.1.2/bin:/usr/local/xcov-1.0.0/bin:$PATH
@end smallexample

Then switch to the Xcov @code{explore} example directory and exercise
the @code{test_queues} test there for your target, thanks to the local
@code{Makefile}:

@smallexample
.../examples/explore $ make TESTS=test_queues TARGET=powerpc-elf
@end smallexample

This performs a build/run/analyze sequence out of which object coverage
results rendered in sources are produced in html format.
@c
No user interaction is required for this specific test.
@c
To get a first idea of what is going on, let's looks at comments Over
the sequence out of the @code{make} invocation above:

@smallexample

# Step 1:  Build an executable program suitable for Qemu. This is a
# -------  regular <target>-gnatmake build with a couple of extra bsp
#          components for startup/io + a dedicated linker script:

powerpc-elf-gcc -c -o start.o ../support/powerpc-elf/start.s
powerpc-elf-gcc -c -g -O1 -fpreserve-control-flow -o c_io.o .../c_io.c

powerpc-elf-gnatmake -g -O1 -fpreserve-control-flow test_queues
 ... -largs start.o c_io.o -Wl,-T../support/powerpc-elf/gnu.ld -nostdlib
[...]
powerpc-elf-objcopy -O binary test_queues test_queues.bin

# Step 2:  Run the '.bin' executable program within the instrumented Qemu,
# -------  requesting the production of an execution '.trace' file:

qemu-system-ppc -nographic -M prep -L . -bios test_queues.bin
                -trace test_queues.trace /dev/null

# Step 3:  Ask xcov to analyze the trace and produce an html version of
# -------  the results, with object coverage branch info rendered on source:

xcov -r test_queues.trace -e test_queues \
         --annotate=html --asm --coverage=branch
mv index.html index-test_queues.html

@end smallexample

The local @code{explore/Makefile} actually just includes a generic
@code{support/Makefile} for all the examples, which you may reuse and
adapt to your specific needs.
@c
We will now get into the @xcov{} features in more details.

For simple cases as in the example above, the @option{-r} and
@option{-e} command line options specify the trace and executable
program files to use, respectively.
@c
Then:

@itemize
@item @option{--coverage}
specifies the kind of information to produce, with variants to support
different kinds of coverage analysis activities (OBC, SDC, ...), and

@item @option{--annotate}
specifies how the selected information should be presented (annotated
source or assembly, html with colors, ...)
@end itemize

@section Object Coverage Analysis

@option{--coverage} accepts variants to request object instruction or
branch coverage reports:

@itemize
@item @option{--coverage=insn}
requests @dfn{Object Instruction Coverage} data, with an indication for
every instruction of whether it has been executed or not.

@item @option{--coverage=branch}
requests @dfn{Object Branch Coverage} data, with extra details about
the directions taken by conditional branch instructions.
@end itemize

@noindent
Then:

@itemize
@item @option{--annotate=asm}
produces annotated assembly code on standard output,

@item @option{--annotate=xcov[+asm]}
produces annotated source files, with the object code for each source
line interspersed if the @code{+asm} variant is selected,

@item @option{--annotate=html[+asm]}
produces annotated sources in html format with colors, @code{+asm}
code expandable from each source line by a click on the annotation, and
an index summarizing the overall coverage status per compilation unit.
@end itemize

@noindent
The following sections provides extra details and examples for each
situation.

In principle, this is all pretty independant of the program
compilation options.
@c
Aggressive optimizations very often make source to object code
associations more difficult, however.
@c
Besides, if source coverage analysis is to be performed as well, the
whole process is simpler if the same compilation options are used, and
these have to be strictly controlled for source coverage.

@subsection @code{--annotate=asm}
@noindent
For branch coverage analysis, @option{--annotate=asm} produces
annotated assembly code for all the program routines on standard output.
@c
The annotations are visible as a special character at the beginning of
each machine code line, with variants for instruction or branch coverage
modes, as described by the following tables.

The Note column contains the annotation character, the ``Means ...''
column contains a short description of the annotation meaning and the
``Coverage'' column qualifies the instruction coverage.

@noindent
For Instruction coverage we have:

@multitable @columnfractions .1 .7 .2
@headitem Note @tab Means ... @tab Coverage
@item '-'
@tab Instruction was never executed
@tab Null
@item '+'
@tab Instruction was executed
@tab Full
@end multitable

@noindent
For Branch coverage, the ``instruction was executed'' case is refined
into several subcases for conditional branch instructions:

@multitable @columnfractions .1 .7 .2
@headitem Note @tab Means ... @tab Coverage
@item '>'
@tab Conditional branch was executed, always taken
@tab Partial
@item 'v'
@tab Conditional branch was executed, never taken
@tab Partial
@item '*'
@tab
Conditional branch was executed, taken and not taken
@tab Full
@end multitable

To illustrate the output format, we will consider the Branch Coverage
outcome for a piece of the Explore example, produced out of a couple of
runs within Qemu for the PowerPC architecture.
@c
The original source of interest is the @code{if} statement which
controls the Station processing termination, upon a Quit request
from the user:

@smallexample

   procedure Run (Sta : Station_Access) is
      ...
      Put ("'P'robe, 'S'tep, Rotate 'L'eft/'R'ight, 'Q'uit ? ");
      Flush;
      Get (C);

      if C = 'Q' or else C = 'q' then
         Kill (Sta.all);
         return;
      else
      ...
@end smallexample

We first run a sample session to exercise Probe, then Quit with 'Q',
and request branch coverage data in assembly format:

@smallexample

... $ make TESTS=explore trace
[Explore runs in Qemu - type 'p', then 'Q']

... $ xcov -r explore.trace -e explore
      --coverage=branch --annotate=asm

@end smallexample

For the code associated with the source bits of interest, This yields
the following assembly coverage report excerpt:


@smallexample
...
<stations__run>:
...
fffc1c0c +:     4b ff e6 7d   bl     0xfffc0288 <text_io__get>
fffc1c10 +:     2f 83 00 51   cmpiw  cr7,r3,0x0051
fffc1c14 *:     41 9e 00 0c   beq-   cr7,0xfffc1c20 <stations__run+00000078>
fffc1c18 +:     2f 83 00 71   cmpiw  cr7,r3,0x0071
fffc1c1c >:     40 9e 00 10   bne-   cr7,0xfffc1c2c <stations__run+00000084>
fffc1c20 +:     7f e3 fb 78   or     r3,r31,r31
fffc1c24 +:     4b ff e7 d1   bl     0xfffc03f4 <actors__kill>
...
@end smallexample

@code{beq} and @code{bne} are two conditional branch instructions,
each associated with one of the two conditions.
@c
In addition to straightforward coverage of the rest of the code, the '*'
for the first branch indicates that it is fully covered and the '>' for
the second branch indicates partial coverage only.
@c
Indeed, both conditions were evaluated to False on the 'p' input, then
on 'Q' the first condition was evaluated to True and the second one was
short-circuited.

As a second experiment, the user quits with 'Q' immediatly, in which
case the first conditional branch is only partially covered and the
second one is not even exercised:

@smallexample
...
<stations__run>:
...
fffc1c0c +:     4b ff e6 7d   bl     0xfffc0288 <text_io__get>
fffc1c10 +:     2f 83 00 51   cmpiw  cr7,r3,0x0051
fffc1c14 >:     41 9e 00 0c   beq-   cr7,0xfffc1c20 <stations__run+00000078>
fffc1c18 -:     2f 83 00 71   cmpiw  cr7,r3,0x0071
fffc1c1c -:     40 9e 00 10   bne-   cr7,0xfffc1c2c <stations__run+00000084>
fffc1c20 +:     7f e3 fb 78   or     r3,r31,r31
fffc1c24 +:     4b ff e7 d1   bl     0xfffc03f4 <actors__kill>
...
@end smallexample

@subsection @code{--annotate=xcov[+asm]}
@noindent
@option{--annotate=xcov} produces annotated source files with the
@code{.xcov} extension in the current directory, one per original
compilation unit.
@c
The annotations are visible as a special character at the beginning of
every source line, which synthesizes the coverage status of all the
machine instructions generated for this line.
@c
These annotations are really meant to convey object code properties,
hence are of a different nature than what the DO-178B structural
coverage criteria refer to.

A source line of code typically translates into multiple machine
instructions, printed next to their associated source line when the
@option{+asm} option extension is used.
@c
We defined a different synthesis of source line from object code
annotations for instruction or branch coverage.
@c
For instruction coverage:

@multitable @columnfractions .1 .8
@headitem Note @tab Means ...
@item '-'
@tab None of the machine instructions associated with the line
was not executed
@item '!'
@tab At least one of the machine instructions associated with the line
was not executed
@item '+'
@tab All the machine instructions associated with the line were executed
@end multitable

@noindent
For branch coverage, the @code{'+'} case is refined into:

@multitable @columnfractions .1 .8
@headitem Note @tab Means ...
@item '>'
@tab Object code includes a single conditional branch, taken
@item 'v'
@tab Object code includes a single conditional branch, not taken
@item '*'
@tab All object code conditional branches were fully covered
@item '?'
@tab Some of object code conditional branches were partially covered
@end multitable

Requires -g

Examples

@subsection @code{--annotate=html[+asm]}

@section Source Coverage Analysis

Capabilities and documentation to be developped.

Compilation options have to be strictly controlled.

Requires extended traces for MCDC, checkpoint info instead 

Focuses on source, through Source Coverage Obligations.

@section Ada Constructs of Note

@subsection Generics

@subsection Inlining

@section GNAT specificities

-g no code change,

Expansions, precise debug info ...

-O1 -fpreserve-control-flow

@section Coverage Data Capitalization

@section Coverage Data Consolidation

@section @code{xcov} command line summary

@chapter Appendices

@section Trace Format Definition

@c *******************************************************************
@c *                          BIBLIOGRAPHY                           *
@c *******************************************************************

@chapter Bibliography

@macro CHILENSKI
John J. Chilenski
@end macro

@macro KURTZ
John L. Kurtz
@end macro

@macro bibdef{entry}
@anchor{\entry\}@strong{[\entry\]}
@end macro

@multitable @columnfractions .1 .8
@item @bibdef{ar07/20}
@tab Object-Oriented Technology Verification Phase 3 Report:
Structural Coverage at the source code and object code levels.
@c
@CHILENSKI{} and @KURTZ{}.
@c
DOT/FAA/AR-07/20.

@item @bibdef{gcc}
@tab GCC: The GNU Compiler Collection.
@c
http://gcc.gnu.org

@item @bibdef{qemu}
@tab QEMU, a Fast and Portable Dynamic Translator.
@c
Fabrice Bellard.
@c
Proceedings of the ``USENIX 2005 Annual Technical Conference, FREENIX
Track'', pp 41-46.
@c
http://bellard.org/qemu/

@end multitable

@bye
