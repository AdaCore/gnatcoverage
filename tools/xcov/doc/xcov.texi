\input texinfo  @c -*-texinfo-*-

@c %**start of header
@c oooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo
@c                                                                            o
@c                            XCOV DOCUMENTATION                              o
@c                                                                            o
@c oooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo

@setfilename xcov.info
@settitle Xcov documentation
@c %**end of header

@c Directory where the Explore guide example is stored
@set explore_dir examples/explore

@c Typeset text to be considered as a term being defined at the point
@c this macro appears.
@macro term{t}
@i{\t\}
@end macro
 
@titlepage
@title Xcov Fundamentals & Users Guide
@end titlepage

@contents

@c ooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo
@node Top
@top  About this Document

@noindent
This document describes the fundamentals of Xcov, a non intrusive
structural coverage analysis framework.

@ref{explore} presents a simple application example, support to
illustrate various points in the subsequent chapters.

@ref{cov-basics} introduces the basic.

@menu
* explore::    The Explore Guide Example
* cov-basics:: Structural Coverage Basics
@end menu


@node explore,cov-basics,Top,Top
@chapter The ``Explore'' Guide Example
@noindent
The Explore example is a toy Ada application we use throughout the Xcov
documentation to introduce and illustrate a number of concepts.
@c
Below is a short functional and organisational description, verbatim from
the sources:

@smallexample
@c @verbatiminclude @value{explore_dir}/overview.ads
@end smallexample

@node cov-basics,,explore,Top
@chapter Structural Coverage Analysis Basics

@section General Definition & Rationale
@noindent
To a first approximation, structural coverage analysis may be viewed as
a software development activity aimed at analysing which pieces of an
application source and/or machine code are exercised by executions of
the application software.
@c
There may be several reasons why such an activity is performed and extra
details about what exactly is to be evaluated.

Our focus here is the use of coverage analysis in software certification
processes such as the DO-178B standard enforced in the civilian avionics
domain.
@c
In this context, the application code and the test sequences are both
derived from a common set of requirements, independently, and structural
coverage analysis is one of the means to confront the pieces.
@c
Essentially, it allows an assessment of the testing campain quality and
helps the identification of various forms of pointless code or of
requirements imprecision/incompleteness,

In the following sections we introduce the elements of a coverage
analysis process together with @term{terms} to be reused throughout this
document.

@section Process Model

@subsection Primary Process Abstractions
@noindent
A typical base coverage analysis process comprises three principal
steps:
@enumerate
@item
A binary @term{executable program} is produced from a set of
@term{sources} by a development toolchain with a compiler, a linker etc.

@item
The program is run within an @term{execution environment}, and this
execution produces @term{raw coverage data} about paths it exercises.
@c
The form of this raw information depends on the coverage analysis toolset
technology.
@c
This is most often binary data.

@item
The raw coverage data is interpreted or @term{mapped} into some user
readable representation.
@end enumerate

As an illustrative example, consider the common GCC/GCOV process, exactly
along those lines: the program is compiled and linked by GCC 
@c @footnote{GCC:The GNU Compiler Collection - http://gcc.gnu.org}
with special command-line options, execution produces a binary data file
and the GCOV tool can then be used to generate annotated sources from
the original files, the executable and the execution data.
@c
Below is an example to illustrate for a simple test of the Explore queues
abstraction, compiled with the GNAT toolchain for Ada:

@smallexample
# Build with gcov related options - produces executable program

    $ gnatmake test_queues.adb -fprofile-arcs -ftest-coverage

# Run program - produces raw coverage data files (queues.gcda, ...)

    $ ./test_queues

# Map to user representation - produces annotated sources (queues.adb.gcov, ...)
 
    $ gcov test_queues
@end smallexample
  
The annotations are in the first column for each source line: @code{-}
indicates there is no associated object code, numbers indicates the number
of times code for this line was executed, and @code{#} signs indicates
object code never executed:

@smallexample

        [...]
        1:    9:procedure Test_Queues is
        -:   10:   package Integer_Queues is new Queues (Data_Type => Integer);
        -:   11:   use Integer_Queues;
        -:   12:
        -:   13:   X : Integer;
        1:   14:   Q : Integer_Queues.Queue (Capacity => 1);
        -:   15:begin
        1:   16:   Push (12, Q);
        1:   17:   Pop (X, Q);
        1:   18:   if X /= 12 then
    #####:   19:      raise Program_Error;
        -:   20:   end if;
        -:   21:end;

@end smallexample

In this excerpt, the never executed code is expected to show up this way,
as it is intended to trigger only when the test didn't behave as it should.
@c
This points at an important distinction to make: the @code{Test_Queues}
procedure in this example is @term{testing code} written to exercise
pieces of the @code{Queues} abstraction, and only the latter an actual
part of the application.
@c
Most of the time, we're only really interested in the coverage results
for such @term{applicative} code.

The production of raw coverage data at run time always implies some sort of
@term{instrumentation} to have the execution produce information it
normally wouldn't produce.
@c
This may be achieved in several possible manners:
@itemize
@item
Explicit statements and data structures to maintain the coverage state
are added to the program sources.
@c
This is what many commercial products do.

@item
The development toolchain inserts extra machine state and instructions in
the program executable code.
@c
This is the GCC/GCOV approach.

@item
The execution environment is setup to produce a trace of the program paths
taken at the machine instruction level, leaving the program code untouched.
@c
This is what solutions based on hardware probes or on instrumented
virtual execution environments do.

@end itemize

There are variants of each technique in the field, each with it's own set
of advantages and drawbacks compared to others.

While this base process applies to many situations, refinements are
useful in some cases, as outlined in the following sections.

@subsection Coverage Data Capitalization
@noindent

@term{Capitalization} denotes all the elements related to the fact that
proper coverage of a common piece of applicative code might require several
test executions, each providing its own partial coverage outcome.
@c
The different tests could for instance be several executions of the same
program with behavior differences caused by external input variations.
@c
They could also be executions of different programs feeding the same
applicative code with different parameters internally.
@c
The common applicative code coverage is the combination of the partial
coverage results, which first need to be stored (capitalized) to be unified
later on.

Consider for instance a common data structure implementation such as
the bounded @code{Queues} Ada package in the Explore example.
@c
To honor a common requirement, it contains simple error handling code so
that an "Ada exception X is raised on attempts to extract an item out of an
empty queue", and we expect this code not to be exercised in regular
executions.
@c
It remains applicative code, still, and even the weakest DO-178B
certification level requires tests to cover it, to make sure that at least
minimal checks on its behavior with respect to requirements were performed.
@c
Something has to be done outside nominal executions in this case.
@c
One possibility is to construct a separate program dedicated to just
testing this abstraction, which would force an artificial queue underflow.
@c
Of course, this is a simple introductory example and the dedicated test
program could well cover the whole package on its own in this case.
@c
Such one-shot full coverage is sometimes not possible in more complex
situations, however, and the example shows it is already partially
impossible with only regular Explore executions.

Besides, even if full coverage a some applicative components could
theortically be achieved from a single execution, it is often just more
convenient or sensible to be able to reach the goal in an incremental
fashion.
@c
In the Explore case, for instance, a strategy like "purpose is to maximize
the entire application coverage by running a minimal number of sessions"
would be a pain and actually go against the requirements based testing
philosophy.
@c
One instead typically runs different sessions to verify different specific
application requirements, each session produces it's own coverage data,
capitalized, and then a capitalization-aware coverage analysis toolset
unifies these partial coverage results into a single view.

@subsection Coverage Data Consolidation
@noindent
Coverage of all the pieces of a final application is often not performed
with all the pieces integrated together.
@c
In complex systems, this integration is a delicate process, not possible
before late stages of the project, and it is often useful or simply
unavoidable to perform coverage analysis on segregated pieces first.
@c
In this context, @term{Consolidation} denotes the process of gathering
the coverage information for the various pieces of a system into a
unified view, for instance to check that proper coverage was achieved
for all the pieces.
@c
Technically, consolidation can be viewed as a set of means to use a
generalized capitalization capability for all the pieces of a system.

The need for coverage data consolidation often correlates with testing
strategies: whether coverage data is obtained from unit testing of
individual components, from integration testing of the system as a whole,
from some intermediate organisation, or possibly from a mix of all these.
@c
Any of these could apply to the Explore example case.

@subsection Process Integration
@noindent
As hinted by the previous sections, coverage analysis is a potentially
complex activity, which requires potentially complex metrics on
potentially complex software involved in potentially complex project
development cycles.

@term{Process integration} refers to the organizaton of the analysis
toolset that will provide consistent and easy access to all the features of
interest for a given project.
@c
The toolset needs to be both powerful enough to provide the desired
functionalities and flexible enough to accomodate the various possible
project organizations in the field.

@section Coverage Analysis Classification
@noindent
We distinguish two broad classes of analysis activities: @term{source}
and @term{object} coverage analysis.
@c
The process always consists in the evaluation of various possible
coverage quantifiers, most often driven by specific objectives.
@c
Every toolsets offers its own spectrum of analysis possibilities, with
variations in the implementation schemes behind the scene, in particular
regarding the instrumentation mode.

@subsection Object Coverage Analysis
@noindent
Object Coverage Analysis focuses on machine object code coverage.
@c
We will distinguish two major related quantifiers:

@itemize
@item @term{Object Instruction Coverage (OIC)},
a quantification of the program machine instructions exercised by a set
of program executions.

@item @term{Object Branch Coverage (OBC)},
OIC + a quantification of the directions taken by each machine
conditional branch instruction in the program as exercised by a set of
executions.
@end itemize

In both cases, results can be rendered on a representation of the
machine code (for instance an annotated assembly language output) or on
a representation of the program sources.
@c
The focus is always on machine code coverage, still, and source
annotations in this context are just a means to organize and hilight
machine code properties of interest for the end user.

@subsection Source Coverage Analysis
@noindent
Source Coverage Analysis focuses on user source code and simply
abstracts the machine code away.
@c
The DO-178B ``structural coverage'' criteria operate at this level,
with three quantifiers defined over three core elements:

@itemize
@item @term{Source statement},
just referred to in the usual programming language sense.

@item @term{Decision},
defined as ``a Boolean expression composed of conditions and zero or
more Boolean operators.''.

@item @term{Condition},
defined as ``a decision without a Boolean operator'', with an extra
detail: ``If a condition appears more than once in a decision, each
occurrence is a distinct condition.''.
@end itemize

@noindent And then:
@itemize
@item @term{Source Statement Coverage (SSC)},
a quantification of the source statements exercised by a set of
program executions.

@item @term{Source Decision Coverage (SDC)},
SSC + a quantification of the values taken by each logical decision as
exercised by a set of program executions + a quantification of which
entry/exit points were exercised as well.

@item @term{Source Modified Condition/Decision Coverage (SMCDC)},
SDC + a quantification of wich conditions were shown to have independant
effect on their decisions out of a set of program executions.
@end itemize

The quantifier names are often used standalone to denote coverage
objectives, for instance ``achieving Source Statement Coverage'' to
denotes covering 100% of the program source statements, and the
``source'' part is often omitted and implicitly assumed.
@c
DO-178B attaches specific structural coverage objectives to different
certification levels this way, with @term{Statement Coverage} at level C,
@term{Decision Coverage} at level B and @term{Modified
Condition/Decision Coverage} at level A.

Below is an simple illustration of the principal differences over a
simple example out of the Explore sources, part of the Robot abstraction
behavior:
@smallexample
   --  Whether execution of CTRL by Robot R is unsafe

   function Unsafe
     (Ctrl : Robot_Control; R : Robot_Access) return Boolean
   is
      Situ : Situation;
   begin
      --  Probe the current situation in SITU and evaluate.
      --  Start by assuming CTRL is safe and adjust.

      Devices.Probe (Situ, R.H.DH);
      declare
         Is_Unsafe : Boolean := False;
      begin
         --  Stepping forward with a rock block on the square ahead
         --  would crash the robot on the block

         if Ctrl.Code = Step_Forward and then Situ.Sqa = Block then
            Is_Unsafe := True;
         end if;

         return Is_Unsafe;
      end;
   end;
@end smallexample

The Statement Coverage criterion requires execution of all the source
statements at least once.
@c
This can be achieved with a single call to the function in this example,
as soon as the boolean decision controlling the @code{if} statement
evaluates to @code{True}.

Decision Coverage requires that every decision has evaluated at least
once to @code{True} and at least once @code{False}, which necessitates
at least two calls in our example, one to exercise the @code{then} part
of the @code{if} statement and one to exercise the implicit null
@code{else} part.
@c
It also requires going through every possible entry and exit point,
without impact of note on the simple example at hand.

Modified Condition/Decision Coverage requires additional variations over
the conditions, and combinations to show that each condition can affect
the decision outcome in an independant manner.
@c
This is expected to be possible with Nconditions+1 evaluations, so
enforces a more precise testing of the expressions structure while
keeping the test base complexity linear with the number of conditions.

@subsection Source vs Object Quantifiers
@noindent
Both kinds of quantifiers have pros and cons, very dependent on the
use context and general purpose.
@c
An interesting and difficult question is that of the possible
``equivalence'' of one with criterion to another one, for some
definition of ``equivalence'' to start with.
@c
For instance, it is established that OBC can sometimes be achieved
with less tests than SMCDC


@c ooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo

@chapter Xcov Fundamentals

@section Instrumentation Level and Raw Coverage Data
@noindent
The core principle in the Xcov framework is to leverage the generation
of raw coverage data by a virtual execution environment instrumented to
produce machine level traces about the code it executes.

The environment would typically be an emulator representative of a real
target machine microprocessor, possibly augmented with extensions to let
it communicate with external devices.
@c
It could also be a pure virtual machine such as existing ones for Java
or Caml like languages.
@c
In any case, the program itself isn't instrumented, so coverage
measurements can be performed on target code as embedded eventually, and
the virtual environment runs on development hosts, which offers a lot of
flexibility.

The raw coverage data out of the execution environment is very low level
information about the executed instruction and branch sequences at the
machine level.
@c
The actual contents may vary, depending on the kind of analysis
anticipated.

@section Object Coverage Analysis
@noindent
To start with, Xcov allows the confrontation of execution traces with
the full machine code available from program files, hence precise object
coverage analysis with both instruction and branch coverage capabilities.
@c
This is achievable with simple traces that can be gathered and
represented in a very efficient manner, schematically as a flat compact
map of status per executed instruction or linear sequence.

The results may first be rendered at the assembly language level, with
annotations for each machine instruction to indicate whether it was
executed or not, and for each conditional branch whether it has been
taken, not taken or both.

Then, provided extra information to establish instruction to source line
correspondance, Xcov is also able to render the object coverage outcome
through source annotations, with source line annnotations derived from
those of all the associated machine instructions.
@c
Typically, a source line is marked as @term{fully}/@term{partially}
covered when all/part of the associated machine instructions were
executed, and the instruction/line correspondance is extracted from
standard DWARF debug information or alike.

@section Source Coverage Analysis
@noindent
Xcov is also designed to allow Source Coverage Analysis, with central
focus on user source code and support for the three DO-178B quantifiers:
Statement Coverage, Decision Coverage and Modified Condition/Decision
Coverage.

Relies on Source Coverage Obligations

Only the way to relate excution traces to obligations differs amongst
levels.


@subsection Base Restrictions and Compiler Assumptions

Base compiler assumption: a conditional branch per condition.
@c
Then:

@enumerate
@item
The set of binary operators allowed over boolean entities is restricted to
the short-circuit operators (@code{and then} + @code{or else} in Ada),

@item
Binary operators over boolean entities may only appear in explicit control
flow decisions (as part of @code{X} in @code{[els]if X, while X, exit when
X} in Ada).

@item
Different kinds of binary operators over boolean entities may not be mixed
together in the same expression (@code{A and then B and then C} is allowed,
@code{A or else B and then C} is not).

@end enumerate

Implications (no expr in assignments).

Position wrt extreme mcdc considerations

@subsection Relaxing constraints with additional compiler support

Expansion of boolean assignments and return statements => relax
restrictions on decision contexts.

Precise debug info to map branches to conditions => relax restrictions
on expression structure.

Source Coverage => Specific compilation options, reasonable for
operational use => possible object analysis on final code.

@chapter Xcov User's Guide

@section Base Process

Compilation options.

@subsection Assembly Annotations

@subsection Source Annotations

@subsection Levels of Results Interpretation

Yes/No vs details 

@section Ada Constructs of Note

@subsection Generics

@subsection Inlining

@section GNAT specificities

-g no code change,

Expansions, precise debug info ...

@section Capitalization

@section Consolidation

@chapter Appendices

@section Trace Format Definition


@bye

