\input texinfo  @c -*-texinfo-*-

@c %**start of header
@c oooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo
@c                                                                            o
@c                            XCOV DOCUMENTATION                              o
@c                                                                            o
@c oooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo

@setfilename xcov.info
@settitle Qcov documentation
@c %**end of header

@set explore_dir examples/explore

@macro term{t}
@i{\t\}
@end macro
 
@titlepage
@title Qcov Fundamentals & Users Guide

@noindent
This document describes the fundamentals of Qcov, a non intrusive
structural coverage analysis framework.

@ref{explore} presents a simple application example to be used as a support
to illustrate various points in the subsequent chapters.

@ref{coverage-basics} introduces the basic.

@end titlepage

@contents

@c ooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo

@node explore
@chapter The ``Explore'' Guide Example
@noindent
The Explore example is a toy Ada application we use throughout the Xcov
documentation to introduce and illustrate a number of concepts.
@c
Below is a short functional and organisational description, verbatim from
the sources:

@smallexample
@verbatiminclude @value{explore_dir}/overview.ads
@end smallexample

@node coverage-basics
@chapter Structural Coverage Analysis Basics

@section General Definition & Rationale
@noindent
To a first approximation, structural coverage analysis may be viewed as a
software development activity aimed at analysing which pieces of an
application source code are exercised by executions of the application
software.
@c
There may be several reasons why such an activity is performed and extra
details about what exactly is to be evaluated.

Our focus here is the use of coverage analysis in software certification
processes such as the DO-178B standard enforced in the civilian avionics
domain.
@c
In this context, the application code and the test sequences are both
derived from a common set of requirements, independently, and structural
coverage analysis is one of the means of confronting the pieces.
@c
Essentially, it allows assessing the testing campain quality and helps the
identification of various forms of pointless code or of requirements
imprecision/incompleteness,

DO-178B distinguishes four certification levels, from A, the strictest, to
D, and defines specific structural coverage objectives for each.
@c
Coverage objectives are defined in terms of @term{coverage criteria}
satisfaction.
@c
Coverage analysis is the process by which one determines if the coverage
objectives are met.
@c
The main coverage criteria per level are as follows:
@itemize
@item
For level C : Statement Coverage
@item
For level B : level C + Decision Coverage
@item
For level A : level B + Modified Condition/Decision Coverage
@end itemize

The precise definition of all the terms involved is out of the scope of
this manual.
@c
Here are the essential ideas by way of a simple example out of the Explore
sources, part of the Robot abstraction behavior:
@smallexample

   function Unsafe
     (Ctrl : Robot_Control; R : Robot_Access) return Boolean
   is
      Situ : Situation;
   begin
      Devices.Probe (Situ, R.H.DH);

      --  Given the current situation in SITU, evaluate whether
      --  the CTRL command is unsafe.  Start by assuming it is not
      --  and adjust.

      declare
         Is_Unsafe : Boolean := False;
      begin
         --  Stepping forward with a rock block on the square ahead
         --  would crash the robot on the block

         if Ctrl.Code = Step_Forward and then Situ.Sqa = Block then
            Is_Unsafe := True;
         end if;

         return Is_Unsafe;
      end;
   end;
@end smallexample

The Statement Coverage criterion requires execution of all the statements
at least once.
@c
This can be achieved with a single call to the function in this example, as
soon as the boolean expression (``decision'' in DO-178B parlance)
controlling the @code{if} statement evaluates to @code{True}.

Decision Coverage requires that every decision has evaluated at least once
to @code{True} and at least once @code{False}, which necessitates at least
two calls in our example.

Modified Condition/Decision Coverage requires additional variations over
the individual boolean atoms in expressions (``conditions'' in DO-178B
parlance), and combinations showing that each condition can affect the
decision outcome in an independant manner.
@c
This is expected to be possible with Nconditions+1 evaluations, and aims at
forcing a more precise testing of the expressions structure while keeping
the test base complexity linear with the number of conditions.

@section Base Process Model
@noindent
In this section we introduce the base elements of a coverage analysis
process together with @term{terms} we will be reusing throughout this
document.

The base process comprises three principal steps:
@enumerate
@item
A binary @term{executable program} is produced from a set of @term{sources}
by a development toolchain with a compiler, a linker etc.

@item
The program is run within an @term{execution environment}, and this
execution produces @term{raw coverage data} about paths it exercises.
@c
The form of this raw information depends on the coverage analysis toolset
technology.
@c
This is most often binary data.

@item
The raw coverage data is interpreted or @term{mapped} into some user
readable representation.
@end enumerate

As an illustrative example, consider the common GCC/GCOV process, exactly
along those lines: the program is compiled and linked by GCC @footnote{GCC:
The GNU Compiler Collection - http://gcc.gnu.org} with special command-line
options, execution produces a binary data file and the GCOV tool can then
be used to generate annotated sources from the original files, the
executable and the execution data.
@c
Below is an example to illustrate for a simple test of the Explore queues
abstraction, compiled with the GNAT toolchain for Ada:

@smallexample

# Build with gcov related options - produces executable program

    $ gnatmake test_queues.adb -fprofile-arcs -ftest-coverage

# Run program - produces raw coverage data files (queues.gcda, ...)

    $ ./test_queues

# Map to user representation - produces annotated sources (queues.adb.gcov, ...)
 
    $ gcov test_queues

@end smallexample
  
The annotations are in the first column for each source line: @code{-}
indicates there is no associated object code, numbers indicates the number
of times code for this line was executed, and @code{#} signs indicates
object code never executed:

@smallexample

        [...]
        1:    9:procedure Test_Queues is
        -:   10:   package Integer_Queues is new Queues (Data_Type => Integer);
        -:   11:   use Integer_Queues;
        -:   12:
        -:   13:   X : Integer;
        1:   14:   Q : Integer_Queues.Queue (Capacity => 1);
        -:   15:begin
        1:   16:   Push (12, Q);
        1:   17:   Pop (X, Q);
        1:   18:   if X /= 12 then
    #####:   19:      raise Program_Error;
        -:   20:   end if;
        -:   21:end;

@end smallexample

In this excerpt, the never executed code is expected to show up this way,
as it is intended to trigger only when the test didn't behave as it should.
@c
This points at an important distinction to make: the @code{Test_Queues}
procedure in this example is @term{testing code} written to exercise pieces
of the @code{Queues} abstraction, and only the latter is going to be part
of the application.
@c
From this perspective, we're only really interested in the coverage results
for such @term{applicative} code, much less in the results for the testing
bits.

The production of raw coverage data at run time always implies some sort of
@term{instrumentation} to have the execution produce information it
normally wouldn't produce.
@c
This may be achieved in several possible manners:
@itemize
@item
Explicit statements maintaining the coverage state are added to the program
sources, this is what many commercial products do.

@item
The development toolchain inserts extra machine state and instructions in
the program executable code, this is the GCC/GCOV approach.

@item
The execution environment is setup to produce a trace of the program paths
taken at the machine instruction level, leaving the program code untouched.

@end itemize

There are variants of each technique in the field, each with it's own set
of advantages and drawbacks compared to others.

@section Process Extensions
@noindent
While the base process works fine for simple cases, refinements are useful
in many situations.
@c
The following sections introduce a number of possible process extensions.

@subsection Coverage Data Capitalization
@noindent
@term{Capitalization} denotes all the elements related to the fact that
proper coverage of a common piece of applicative code might require several
test executions, each providing its own partial coverage outcome.
@c
The different tests could for instance be several executions of the same
program with behavior differences caused by external input variations.
@c
They could also be executions of different programs feeding the same
applicative code with different parameters internally.
@c
The common applicative code coverage is the combination of the partial
coverage results, which first need to be stored (capitalized) to be unified
later on.

Consider for instance a common data structure implementation such as
the bounded @code{Queues} Ada package in the Explore example.
@c
To honor a common requirement, it contains simple error handling code so
that an "Ada exception X is raised on attempts to extract an item out of an
empty queue", and we expect this code not to be exercised in regular
executions.
@c
It remains applicative code, still, and even the weakest DO-178B
certification level requires tests to cover it, to make sure that at least
minimal checks on its behavior with respect to requirements were performed.
@c
Something has to be done outside nominal executions in this case.
@c
One possibility is to construct a separate program dedicated to just
testing this abstraction, which would force an artificial queue underflow.
@c
Of course, this is a simple introductory example and the dedicated test
program could well cover the whole package on its own in this case.
@c
Such one-shot full coverage is sometimes not possible in more complex
situations, however, and the example shows it is already partially
impossible with only regular Explore executions.

Besides, even if full coverage a some applicative components could
theortically be achieved from a single execution, it is often just more
convenient or sensible to be able to reach the goal in an incremental
fashion.
@c
In the Explore case, for instance, a strategy like "purpose is to maximize
the entire application coverage by running a minimal number of sessions"
would be a pain and actually go against the requirements based testing
philosophy.
@c
One instead typically runs different sessions to verify different specific
application requirements, each session produces it's own coverage data,
capitalized, and then a capitalization-aware coverage analysis toolset
unifies these partial coverage results into a single view.

@subsection Coverage Data Consolidation
@noindent
Coverage data @term{consolidation} relates to the fact that coverage of all
the pieces of a final application is often not performed with all the
pieces integrated together.
@c
In complex systems, this integration is a delicate process, not possible
before late stages of the project, and it is often useful or simply
unavoidable to perform coverage analysis on segregated pieces first.
@c
Consolidation, in this context, denotes the process of gathering the
coverage information for the various pieces into a unified view, or of
checking that there is relevant coverage data for all the bits of a
final system of interest.
@c
Technically, consolidation can be viewed as a set of means to use a
generalized capitalization capability for all the pieces of a system.

The need for coverage data consolidation often correlates with testing
strategies: whether coverage data is obtained from unit testing of
individual components, from integration testing of the system as a whole,
from some intermediate organisation, or possibly from a mix of all these.
@c
Any of these could apply to the Explore example case.

@section Process Integration
@noindent
As hinted by the previous sections, coverage analysis is a potentially
complex activity: indeed, depending on the context, it involves potentially
complex metrics, on potentially complex software involved in potentially
complex project development cycles.

@term{Process integration} refers to the organizaton of the analysis
toolset that will provide consistent and easy access to all the features of
interest for a given project.
@c
The toolset needs to be both powerful enough to provide the desired
functionalities and flexible enough to accomodate the various possible
project organizations in the field.

@c ooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo

@chapter Qcov Fundamentals

@section Key characteristics

The core principle is to leverage the generation of raw coverage data by an
execution environment instrumented to produce traces about the code it
executes.
@c
Typically, this will be a virtual environment such as an emulator
representative of the final target processor.
@c
The program itself isn't instrumented, so coverage measurements are
performed on target code, as embedded eventually, and the virtual
environment runs on development hosts, which offers a lot of flexibility.

The raw coverage data out of the execution environment is very low level
information about the executed instruction and branch sequences at the
object level, efficient representation of bits like

@smallexample
program was "explore"
executed straight sequence between 0x1230 and 0x1250
conditional branch at 0x1254, taken
executed straight sequence between 0x2840 and 0x2860
conditional branch at 0x2864, not taken
...
@end smallexample

To start with, confronting this with the full executable code available
from the program file allows precise assembly/object level coverage
analysis, with both instruction and branch coverage capabilities.
@c
Then, mapping to source level coverage outputs is performed thanks to data
aside the executable code, such as standard DWARF debug information, to
associate each object instruction with its source line number.
@c
In this context, we define notions of coverage completeness at both the
object and the source levels, together with mappings from the former to
the latter.

At the object level, there are two aspects to code coverage completeness:
for every machine instruction, whether it has been executed or not, and for
conditional branch instruction, when executed, whether it has been taken,
not taken, or both.
@c
A single conditional branch instruction is said to be @term{fully covered},
or just @term{covered}, when it has been taken at least once and not taken
at least once.
@c
It is said to be only @term{partially covered} otherwise.
@c
Other instructions are said to be covered as soon as they have been
executed at least once.
@c
For a set of machine instructions, @term{full instruction coverage} refers
to the execution of all the instructions in the set and @term{full branch
coverage} refers to the status of all the branch instructions in the set.

Object to source level coverage mappings are rules that define the
coverage completeness for a source line from the coverage completeness of
all the associated machine instructions.
@c
We defined one for each certification level of the DO-178B standard.
@c
Let us consider an example to illustrate:


@c
Only the mapping differs amongst levels

A key aspect of this technology is the mapping of instruction and branch
coverage on uninstrumented machine code up to source level information.

@section Object & Source level Coverage

Different ways to consider variations:
@itemize
@item
implementation mechanisms - source vs object level instrumentation, program
or environment in the latter case
@item
user analysis level: whether the user eventually conducts its analysis on
source constructs or on machine code.
@end itemize

Qcov uses object based implementation mechanisms with execution
environment instrumentation, and allows both source and object level
analysis.

@section From OBC to Statement Coverage

This is straightforward for statement coverage

@section From OBC to Decision Coverage

Pretty straightforward as well.

What about the entry/exit point buisness ???

@section From OBC to Modified Condition/Decision Coverage

Tricky issues. MCDC variants. Subtle balance between compiler features
and source code restrictions.

Examples ...

@subsection Base Restrictions and Compiler Assumptions

Base compiler assumption: a conditional branch per condition.
@c
Then:

@enumerate
@item
The set of binary operators allowed over boolean entities is restricted to
the short-circuit operators (@code{and then} + @code{or else} in Ada),

@item
Binary operators over boolean entities may only appear in explicit control
flow decisions (as part of @code{X} in @code{[els]if X, while X, exit when
X} in Ada).

@item
Different kinds of binary operators over boolean entities may not be mixed
together in the same expression (@code{A and then B and then C} is allowed,
@code{A or else B and then C} is not).

@end enumerate

Implications (no expr in assignments).

Position wrt extreme mcdc considerations

@subsection Relaxing constraints with additional compiler support

Expansion of boolean assignments and return statements => relax
restrictions on decision contexts.

Precise debug info to map branches to conditions => relax restrictions
on expression structure.


@chapter Qcov User's Guide

@section Base Process

Compilation options.

@subsection Assembly Annotations

@subsection Source Annotations

@subsection Levels of Results Interpretation

Yes/No vs details 

@section Ada Constructs of Note

@subsection Generics

@subsection Inlining

@section GNAT specificities

-g no code change,

Expansions, precise debug info ...

@section Capitalization

@section Consolidation

@chapter Appendices

@section Trace Format Definition


@bye

